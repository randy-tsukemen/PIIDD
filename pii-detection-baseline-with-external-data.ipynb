{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02057311",
   "metadata": {
    "papermill": {
     "duration": 0.014845,
     "end_time": "2024-01-23T15:50:55.596977",
     "exception": false,
     "start_time": "2024-01-23T15:50:55.582132",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### This notebook is modified from <a href=\"https://www.kaggle.com/code/leonshangguan/modify-of-pii-detect-study\">Modify of PII Detect Study</a>, <a href=\"https://www.kaggle.com/code/pjmathematician/pii-eda-presidio-baseline\">PII EDA Presidio Baseline</a> and <a href=\"https://www.kaggle.com/code/yunsuxiaozi/pii-detect-study-notebook\">PII detect study notebook</a>. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c054ffb2",
   "metadata": {
    "papermill": {
     "duration": 0.013388,
     "end_time": "2024-01-23T15:50:55.625300",
     "exception": false,
     "start_time": "2024-01-23T15:50:55.611912",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modifications \n",
    "\n",
    "Firstly, big thanks to the users who provided the notebooks above. This notebook is merely adding some utility code to make a solid baseline that other users may iterate on, but all the heavy lifting was done by the above notebooks.\n",
    "\n",
    "I encapsulated the analyzer in a class, and added code to run the analyzer on (potentially) both the training and test set. I also added validation code, so that we can analyze the performance of the analyzer on the training set.\n",
    "\n",
    "I also added a global configuration for ease of testing, which allows the user to switch between training and inference mode. Additionally, I incorporated the external data that [https://www.kaggle.com/alejopaullier](@moth) kindly provided in his discussion post.\n",
    "\n",
    "For now, the business logic roughly stays the same as the Modify of PII Detect Study notebook that I used beforehand.\n",
    "\n",
    "## Resources\n",
    "\n",
    "* Customizing the presidio analyzer: https://microsoft.github.io/presidio/samples/python/customizing_presidio_analyzer/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030c172b",
   "metadata": {
    "papermill": {
     "duration": 0.013516,
     "end_time": "2024-01-23T15:50:55.653628",
     "exception": false,
     "start_time": "2024-01-23T15:50:55.640112",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Version History\n",
    "\n",
    "- v16: Original baseline\n",
    "- v17: Changed score thresholds for patterns from 0.5 -> 0.8\n",
    "- v20: fixed bug in evaluation code\n",
    "- v21: changed url regex to not require \"www\"\n",
    "- v23: reverted v21, added @amed's metric code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfd83aa",
   "metadata": {
    "papermill": {
     "duration": 0.014154,
     "end_time": "2024-01-23T15:50:55.681820",
     "exception": false,
     "start_time": "2024-01-23T15:50:55.667666",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41c4ce8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T15:50:55.711957Z",
     "iopub.status.busy": "2024-01-23T15:50:55.711500Z",
     "iopub.status.idle": "2024-01-23T15:50:55.727661Z",
     "shell.execute_reply": "2024-01-23T15:50:55.726389Z"
    },
    "papermill": {
     "duration": 0.036196,
     "end_time": "2024-01-23T15:50:55.732355",
     "exception": false,
     "start_time": "2024-01-23T15:50:55.696159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    \"\"\"\n",
    "    > General Options\n",
    "    \"\"\"\n",
    "    # global seed\n",
    "    seed = 42\n",
    "    # number of samples to use for testing purposes\n",
    "    # if None, we use the whole training dataset\n",
    "    samples_testing = None\n",
    "    # flag to indicate whether to use the external training dataset\n",
    "    # or just to use the original data\n",
    "    use_external_train_data = True\n",
    "    # whether to run the algorithm on the training set and do subsequent validation\n",
    "    # with 6.8k rows, this takes almost 50 minutes to run\n",
    "    run_on_train_data = True\n",
    "    \n",
    "    \"\"\"\n",
    "    > Analyzer Options\n",
    "    \"\"\"\n",
    "    # score threshold for patterns\n",
    "    address_pattern_score = 0.8\n",
    "    email_pattern_score = 0.8\n",
    "    url_pattern_score = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d6d039",
   "metadata": {
    "papermill": {
     "duration": 0.013478,
     "end_time": "2024-01-23T15:50:55.761883",
     "exception": false,
     "start_time": "2024-01-23T15:50:55.748405",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74794fdf",
   "metadata": {
    "papermill": {
     "duration": 0.013493,
     "end_time": "2024-01-23T15:50:55.790041",
     "exception": false,
     "start_time": "2024-01-23T15:50:55.776548",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Install presidio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c999f4b7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-23T15:50:55.826901Z",
     "iopub.status.busy": "2024-01-23T15:50:55.826138Z",
     "iopub.status.idle": "2024-01-23T15:51:18.629017Z",
     "shell.execute_reply": "2024-01-23T15:51:18.627404Z"
    },
    "papermill": {
     "duration": 22.825206,
     "end_time": "2024-01-23T15:51:18.632362",
     "exception": false,
     "start_time": "2024-01-23T15:50:55.807156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#安装python库 presidio_analyzer 不从python库里下载,而是从给定的链接处下载,更新到最新版本,并减少输出信息.\n",
    "!pip install -U -q presidio_analyzer --no-index --find-links=file:///kaggle/input/presidio-wheels/presidio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc903b3",
   "metadata": {
    "papermill": {
     "duration": 0.013465,
     "end_time": "2024-01-23T15:51:18.659752",
     "exception": false,
     "start_time": "2024-01-23T15:51:18.646287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Import  necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "850b5f58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T15:51:18.689495Z",
     "iopub.status.busy": "2024-01-23T15:51:18.688228Z",
     "iopub.status.idle": "2024-01-23T15:51:28.040004Z",
     "shell.execute_reply": "2024-01-23T15:51:28.038547Z"
    },
    "papermill": {
     "duration": 9.370109,
     "end_time": "2024-01-23T15:51:28.043203",
     "exception": false,
     "start_time": "2024-01-23T15:51:18.673094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from presidio_analyzer import AnalyzerEngine\n",
    "from presidio_analyzer.nlp_engine import NlpEngineProvider\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "import random\n",
    "import pprint\n",
    "import re\n",
    "import gc\n",
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import fbeta_score, classification_report, confusion_matrix\n",
    "\n",
    "from presidio_analyzer import AnalyzerEngine, PatternRecognizer, EntityRecognizer, Pattern, RecognizerResult\n",
    "from presidio_analyzer.recognizer_registry import RecognizerRegistry\n",
    "from presidio_analyzer.nlp_engine import NlpEngine, SpacyNlpEngine, NlpArtifacts\n",
    "from presidio_analyzer.context_aware_enhancers import LemmaContextAwareEnhancer\n",
    "\n",
    "from dateutil import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c0476c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T15:51:28.072897Z",
     "iopub.status.busy": "2024-01-23T15:51:28.072052Z",
     "iopub.status.idle": "2024-01-23T15:51:28.077437Z",
     "shell.execute_reply": "2024-01-23T15:51:28.076377Z"
    },
    "papermill": {
     "duration": 0.02298,
     "end_time": "2024-01-23T15:51:28.079985",
     "exception": false,
     "start_time": "2024-01-23T15:51:28.057005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db169a0",
   "metadata": {
    "papermill": {
     "duration": 0.012779,
     "end_time": "2024-01-23T15:51:28.106142",
     "exception": false,
     "start_time": "2024-01-23T15:51:28.093363",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define Metric (F1 Beta Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a96d8579",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T15:51:28.135557Z",
     "iopub.status.busy": "2024-01-23T15:51:28.134597Z",
     "iopub.status.idle": "2024-01-23T15:51:28.146212Z",
     "shell.execute_reply": "2024-01-23T15:51:28.145044Z"
    },
    "papermill": {
     "duration": 0.029287,
     "end_time": "2024-01-23T15:51:28.148859",
     "exception": false,
     "start_time": "2024-01-23T15:51:28.119572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Big thanks to \n",
    "# https://www.kaggle.com/code/amedprof/pii-evaluation-metric?scriptVersionId=160040455\n",
    "def pii_fbeta_score(pred_df, gt_df,beta=5):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - pred_df (DataFrame): DataFrame containing predicted PII labels.\n",
    "    - gt_df (DataFrame): DataFrame containing ground truth PII labels.\n",
    "    - beta (float): The beta parameter for the F-beta score, controlling the trade-off between precision and recall.\n",
    "\n",
    "    Returns:\n",
    "    - float: Micro F-beta score.\n",
    "    \"\"\"   \n",
    "    df = pred_df.merge(gt_df,how='outer',on=['document',\"token\"],suffixes=('_pred','_gt'))\n",
    "\n",
    "    df['cm'] = \"\"\n",
    "\n",
    "    df.loc[df.label_gt.isna(),'cm'] = \"FP\"\n",
    "\n",
    "\n",
    "    df.loc[df.label_pred.isna(),'cm'] = \"FN\"\n",
    "    df.loc[(df.label_gt.notna()) & (df.label_gt!=df.label_pred),'cm'] = \"FN\"\n",
    "\n",
    "    df.loc[(df.label_pred.notna()) & (df.label_gt.notna()) & (df.label_gt==df.label_pred),'cm'] = \"TP\"\n",
    "    \n",
    "    FP = (df['cm']==\"FP\").sum()\n",
    "    FN = (df['cm']==\"FN\").sum()\n",
    "    TP = (df['cm']==\"TP\").sum()\n",
    "\n",
    "    s_micro = (1+(beta**2))*TP/(((1+(beta**2))*TP) + ((beta**2)*FN) + FP)\n",
    "\n",
    "    return s_micro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6014556f",
   "metadata": {
    "papermill": {
     "duration": 0.012862,
     "end_time": "2024-01-23T15:51:28.175137",
     "exception": false,
     "start_time": "2024-01-23T15:51:28.162275",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f489c73",
   "metadata": {
    "papermill": {
     "duration": 0.012913,
     "end_time": "2024-01-23T15:51:28.201529",
     "exception": false,
     "start_time": "2024-01-23T15:51:28.188616",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80216fff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T15:51:28.231202Z",
     "iopub.status.busy": "2024-01-23T15:51:28.230228Z",
     "iopub.status.idle": "2024-01-23T15:51:31.717094Z",
     "shell.execute_reply": "2024-01-23T15:51:31.715132Z"
    },
    "papermill": {
     "duration": 3.505296,
     "end_time": "2024-01-23T15:51:31.720350",
     "exception": false,
     "start_time": "2024-01-23T15:51:28.215054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_df):6807, train_df[0].keys(): ['document', 'full_text', 'tokens', 'trailing_whitespace', 'labels']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_df = json.load(open(\"/kaggle/input/pii-detection-removal-from-educational-data/train.json\"))\n",
    "print(f\"len(train_df):{len(train_df)}, train_df[0].keys(): {list(train_df[0].keys())}\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "test_df = json.load(open('/kaggle/input/pii-detection-removal-from-educational-data/test.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae433b37",
   "metadata": {
    "papermill": {
     "duration": 0.013821,
     "end_time": "2024-01-23T15:51:31.748538",
     "exception": false,
     "start_time": "2024-01-23T15:51:31.734717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load External Data (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d801108d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T15:51:31.846183Z",
     "iopub.status.busy": "2024-01-23T15:51:31.845709Z",
     "iopub.status.idle": "2024-01-23T15:51:39.025611Z",
     "shell.execute_reply": "2024-01-23T15:51:39.023855Z"
    },
    "papermill": {
     "duration": 7.198936,
     "end_time": "2024-01-23T15:51:39.028741",
     "exception": false,
     "start_time": "2024-01-23T15:51:31.829805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CONFIG.use_external_train_data:\n",
    "    # Convert the \"stringified lists\" in the columns to proper Python lists\n",
    "    df_train_external = pd.read_csv('/kaggle/input/pii-external-dataset/pii_dataset.csv', converters={\n",
    "        'tokens': literal_eval, \n",
    "        'labels': literal_eval, \n",
    "        'trailing_whitespace': literal_eval\n",
    "    })\n",
    "    df_train_external.rename(columns={'text': 'full_text'}, inplace=True)\n",
    "    # convert to format similar to how we load in the original data\n",
    "    df_train_external = df_train_external.to_dict('records')\n",
    "    train_df.extend(df_train_external)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c270d6",
   "metadata": {
    "papermill": {
     "duration": 0.013199,
     "end_time": "2024-01-23T15:51:39.055762",
     "exception": false,
     "start_time": "2024-01-23T15:51:39.042563",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sample Data (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22b3a243",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T15:51:39.084810Z",
     "iopub.status.busy": "2024-01-23T15:51:39.084418Z",
     "iopub.status.idle": "2024-01-23T15:51:39.090147Z",
     "shell.execute_reply": "2024-01-23T15:51:39.088555Z"
    },
    "papermill": {
     "duration": 0.023625,
     "end_time": "2024-01-23T15:51:39.092961",
     "exception": false,
     "start_time": "2024-01-23T15:51:39.069336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CONFIG.samples_testing != None:\n",
    "    train_df = random.sample(train_df, CONFIG.samples_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a225701e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T15:51:39.122828Z",
     "iopub.status.busy": "2024-01-23T15:51:39.122418Z",
     "iopub.status.idle": "2024-01-23T15:51:41.076803Z",
     "shell.execute_reply": "2024-01-23T15:51:41.075162Z"
    },
    "papermill": {
     "duration": 1.972854,
     "end_time": "2024-01-23T15:51:41.079547",
     "exception": false,
     "start_time": "2024-01-23T15:51:39.106693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df length: 10189\n",
      "labels: {'I-ID_NUM', 'B-ID_NUM', 'B-USERNAME', 'I-PHONE_NUM', 'I-URL_PERSONAL', 'B-EMAIL', 'B-NAME_STUDENT', 'O', 'B-PHONE_NUM', 'B-STREET_ADDRESS', 'I-NAME_STUDENT', 'B-URL_PERSONAL', 'I-STREET_ADDRESS'}\n",
      "-------------------------\n",
      "label_counts: {'O': 5932015, 'B-NAME_STUDENT': 9451, 'I-NAME_STUDENT': 5400, 'B-URL_PERSONAL': 110, 'B-EMAIL': 2934, 'B-ID_NUM': 78, 'I-URL_PERSONAL': 1, 'B-USERNAME': 6, 'B-PHONE_NUM': 1861, 'I-PHONE_NUM': 2616, 'B-STREET_ADDRESS': 2688, 'I-STREET_ADDRESS': 6155, 'I-ID_NUM': 1}\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_df length:\", len(train_df))\n",
    "\n",
    "labels = set()\n",
    "label_counts = {}\n",
    "for i in range(len(train_df)):\n",
    "    labels.update(train_df[i]['labels'])\n",
    "    for label in train_df[i]['labels']:\n",
    "        if label in label_counts:\n",
    "            label_counts[label] += 1\n",
    "        else:\n",
    "            label_counts[label] = 1\n",
    "            \n",
    "print(f\"labels: {labels}\")\n",
    "print('-'*25)\n",
    "print(f\"label_counts: {label_counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578f4126",
   "metadata": {
    "papermill": {
     "duration": 0.013351,
     "end_time": "2024-01-23T15:51:41.106820",
     "exception": false,
     "start_time": "2024-01-23T15:51:41.093469",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c56b7f4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T15:51:41.136524Z",
     "iopub.status.busy": "2024-01-23T15:51:41.135987Z",
     "iopub.status.idle": "2024-01-23T15:51:41.148029Z",
     "shell.execute_reply": "2024-01-23T15:51:41.146932Z"
    },
    "papermill": {
     "duration": 0.02971,
     "end_time": "2024-01-23T15:51:41.150345",
     "exception": false,
     "start_time": "2024-01-23T15:51:41.120635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_valid_date(text):\n",
    "    try:\n",
    "        # Attempt to parse the text as a date\n",
    "        parsed_date = parser.parse(text)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def tokens2index(row):\n",
    "    tokens  = row['tokens']\n",
    "    start_ind = []\n",
    "    end_ind = []\n",
    "    prev_ind = 0\n",
    "    for tok in tokens:\n",
    "        start = prev_ind + row['full_text'][prev_ind:].index(tok)\n",
    "        end = start+len(tok)\n",
    "        start_ind.append(start)\n",
    "        end_ind.append(end)\n",
    "        prev_ind = end\n",
    "    return start_ind, end_ind\n",
    "\n",
    "# binary search\n",
    "def find_or_next_larger(arr, target):\n",
    "    left, right = 0, len(arr) - 1\n",
    "\n",
    "    while left <= right:\n",
    "        mid = (left + right) // 2\n",
    "\n",
    "        if arr[mid] == target:\n",
    "            return mid\n",
    "        elif arr[mid] < target:\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            right = mid - 1\n",
    "    return left\n",
    "\n",
    "def count_trailing_whitespaces(word):\n",
    "    return len(word) - len(word.rstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da5dec8",
   "metadata": {
    "papermill": {
     "duration": 0.013547,
     "end_time": "2024-01-23T15:51:41.177503",
     "exception": false,
     "start_time": "2024-01-23T15:51:41.163956",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create Analyzer\n",
    "\n",
    "For ease of code, we encapsulate the analyzer code in a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d54edb87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T15:51:41.207713Z",
     "iopub.status.busy": "2024-01-23T15:51:41.206767Z",
     "iopub.status.idle": "2024-01-23T15:51:41.240984Z",
     "shell.execute_reply": "2024-01-23T15:51:41.239482Z"
    },
    "papermill": {
     "duration": 0.053094,
     "end_time": "2024-01-23T15:51:41.244093",
     "exception": false,
     "start_time": "2024-01-23T15:51:41.190999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyAnalyzer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        ## Initialize the analyzer\n",
    "        configuration = {\n",
    "            \"nlp_engine_name\": \"spacy\",\n",
    "            \"models\": [{\"lang_code\": \"en\", \"model_name\": \"en_core_web_lg\"}],\n",
    "        }\n",
    "        \n",
    "        # Create NLP engine based on configuration\n",
    "        provider = NlpEngineProvider(nlp_configuration=configuration)\n",
    "        nlp_engine = provider.create_engine()\n",
    "\n",
    "        # create address recognizer\n",
    "        address_regex = r'\\b\\d+\\s+\\w+(\\s+\\w+)*\\s+((st(\\.)?)|(ave(\\.)?)|(rd(\\.)?)|(blvd(\\.)?)|(ln(\\.)?)|(ct(\\.)?)|(dr(\\.)?))\\b'\n",
    "        address_pattern = Pattern(name=\"address\", regex=address_regex, score = CONFIG.address_pattern_score)\n",
    "        address_recognizer = PatternRecognizer(supported_entity=\"ADDRESS_CUSTOM\", patterns = [address_pattern])\n",
    "\n",
    "        # create email recognizer\n",
    "        email_regex = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "        email_pattern = Pattern(name=\"email address\", regex=email_regex, score = CONFIG.email_pattern_score)\n",
    "        email_recognizer = PatternRecognizer(supported_entity=\"EMAIL_CUSTOM\", patterns = [email_pattern])\n",
    "\n",
    "        # create url recognizer \n",
    "        url_regex = r'https?://\\S+|www\\.\\S+'\n",
    "#         url_regex = r'https?:\\/\\/[a-zA-Z1-9.\\?\\=\\&]+'\n",
    "        url_pattern = Pattern(name=\"url\", regex=url_regex, score=CONFIG.url_pattern_score)\n",
    "        url_recognizer = PatternRecognizer(supported_entity=\"URL_CUSTOM\", patterns = [url_pattern])\n",
    "\n",
    "        registry = RecognizerRegistry()\n",
    "        registry.load_predefined_recognizers()\n",
    "        registry.add_recognizer(address_recognizer)\n",
    "        registry.add_recognizer(email_recognizer)\n",
    "        registry.add_recognizer(url_recognizer)\n",
    "\n",
    "        # Pass the created NLP engine and supported_languages to the AnalyzerEngine\n",
    "        self.analyzer = AnalyzerEngine(\n",
    "            nlp_engine=nlp_engine, \n",
    "            supported_languages=[\"en\"],\n",
    "            registry=registry\n",
    "        )\n",
    "        \n",
    "        ## Initialize the black list\n",
    "        self.black_list = [\"wikipedia\", \"coursera\", \".pdf\", \".PDF\", \"article\", \n",
    "                           \".png\", \".gov\", \".work\", \".ai\", \".firm\", \".arts\", \n",
    "                           \".store\", \".rec\", \".biz\", \".travel\" ]\n",
    "        \n",
    "     \n",
    "    def predict_tokens(self, df_: list) -> pd.DataFrame:\n",
    "        \"\"\"Predict the tokens that have PII in the dataframe.\"\"\"\n",
    "        \n",
    "        PHONE_NUM, NAME_STUDENT, URL_PERSONAL, EMAIL, STREET_ADDRESS, ID_NUM, USERNAME = [],[],[],[],[],[], []\n",
    "\n",
    "        preds = []\n",
    "        #查找每个词分词后的起始位置和终点位置\n",
    "        for i in tqdm(range(len(df_)), desc=\"Processing tokens2index\"):\n",
    "            start, end = tokens2index(df_[i])\n",
    "            df_[i]['start'] = start\n",
    "            df_[i]['end'] = end\n",
    "\n",
    "        for i, d in tqdm(enumerate(df_), total=len(df_), desc=\"Analyzing entities\"):\n",
    "            #results:[type: PERSON, start: 22, end: 37, score: 0.85]\n",
    "            results = self.analyzer.analyze(text=d['full_text'],\n",
    "                                   entities=[\n",
    "                                             #\"PHONE_NUMBER\", \n",
    "                                             \"PERSON\", \n",
    "                                             \"URL_CUSTOM\", #\"IP_ADDRESS\", #\"URL\",\n",
    "                                             \"EMAIL_ADDRESS\", \"EMAIL_CUSTOM\", \n",
    "                                             \"ADDRESS_CUSTOM\",\n",
    "                                             \"US_SSN\", \"US_ITIN\", \"US_PASSPORT\", \"US_BANK_NUMBER\",\n",
    "                                             \"USERNAME\"],\n",
    "                                   language='en',\n",
    "        #                            score_threshold=0.2,\n",
    "                                    )\n",
    "            pre_preds = []\n",
    "            for r in results:#遍历找到过的每个实体,r:[type: PERSON, start: 22, end: 37, score: 0.85]\n",
    "                #就是第s个词就是某个实体的开始\n",
    "                s = find_or_next_larger(d['start'], r.start)#d['start'][s]=r.start\n",
    "                end = r.end#实体终点\n",
    "                word = d['full_text'][r.start:r.end]#文本里找单词\n",
    "                end = end - count_trailing_whitespaces(word)#end减去尾部的空格就是单词自身尾部的下标\n",
    "                temp_preds = [s]#实体单词的集合从第s个单词开始,然后连续几个单词?\n",
    "                try:\n",
    "                    #实体可能不是一个单词,分词的下一个单词如果还没有到达实体的尾部,就把下一个单词加上\n",
    "                    while d['end'][s+1] <= end:\n",
    "                        temp_preds.append(s+1)\n",
    "                        s +=1\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                #找出来的实体是什么,我们就给它打对应的标签\n",
    "                tmp = False\n",
    "\n",
    "                if r.entity_type == 'USERNAME':\n",
    "                    label =  'USERNAME'\n",
    "                    USERNAME.append(d['full_text'][r.start:r.end])\n",
    "\n",
    "        #         if r.entity_type == 'PHONE_NUMBER':\n",
    "        #             #检查是不是日期类型\n",
    "        #             if is_valid_date(word):\n",
    "        #                 continue\n",
    "        #             label =  'PHONE_NUM'\n",
    "        #             PHONE_NUM.append(d['full_text'][r.start:r.end])\n",
    "\n",
    "                if r.entity_type == 'PERSON':\n",
    "                    label =  'NAME_STUDENT'\n",
    "                    NAME_STUDENT.append(d['full_text'][r.start:r.end])\n",
    "\n",
    "                if r.entity_type == 'ADDRESS_CUSTOM':\n",
    "                    label = 'STREET_ADDRESS'\n",
    "                    STREET_ADDRESS.append(d['full_text'][r.start:r.end])\n",
    "\n",
    "                if r.entity_type == 'US_SSN' or r.entity_type == 'US_ITIN' or r.entity_type == 'US_PASSPORT' or r.entity_type == 'US_BANK_NUMBER':\n",
    "                    label = 'ID_NUM'\n",
    "                    ID_NUM.append(d['full_text'][r.start:r.end])\n",
    "\n",
    "                if r.entity_type == 'EMAIL_ADDRESS' or r.entity_type == 'EMAIL_CUSTOM':\n",
    "                    label = 'EMAIL'\n",
    "                    EMAIL.append(d['full_text'][r.start:r.end])\n",
    "\n",
    "                if r.entity_type == 'URL_CUSTOM':# or r.entity_type == 'IP_ADDRESS' or \"http\" in word:\n",
    "                    #去除掉黑名单里的标签\n",
    "                    for w in self.black_list:\n",
    "                        if w in word:\n",
    "                            tmp = True\n",
    "                            break\n",
    "\n",
    "                    label = 'URL_PERSONAL'\n",
    "                    URL_PERSONAL.append(d['full_text'][r.start:r.end])\n",
    "\n",
    "                if tmp:\n",
    "                    continue\n",
    "\n",
    "\n",
    "                #取出实体中的一个分词的下标\n",
    "                for p in temp_preds:\n",
    "                    if len(pre_preds) > 0:#第2次及以后经过这里.\n",
    "                        \"\"\"\n",
    "                        新开始一个r的时候,pre_preds[-1]['rlabel']还是上一个实体的r.entity_type\n",
    "                        此时也许会不等于这个实体的r.entity_type,换句话说,第一个等号就是还在同一个实体里.\n",
    "                        p - pre_preds[-1]['token']==1就是连续的意思\n",
    "                        \"\"\"\n",
    "                        if pre_preds[-1]['rlabel'] == r.entity_type and (p - pre_preds[-1]['token']==1):\n",
    "                            label_f = \"I-\"+label#实体的中间位置\n",
    "                        else:\n",
    "                            label_f = \"B-\"+label#否则就是下一个实体的开始\n",
    "                    else:#第一个label是起始位置,故标记为‘B-’\n",
    "                        label_f = \"B-\"+label\n",
    "                    #保存document,从第p个单词开始,标签为label_f\n",
    "                    pre_preds.append(({\n",
    "                            \"document\":d['document'],\n",
    "                            \"token\":p,\n",
    "                            \"label\":label_f,\n",
    "                            \"rlabel\":r.entity_type#实体的类型\n",
    "                        }))\n",
    "            preds.extend(pre_preds)#遍历完这个数据之后,将所有找到的实体做汇总\n",
    "            \n",
    "        preds_df = pd.DataFrame(preds).iloc[:,:-1].reset_index()\n",
    "        return preds_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e441bc8e",
   "metadata": {
    "papermill": {
     "duration": 0.013468,
     "end_time": "2024-01-23T15:51:41.271178",
     "exception": false,
     "start_time": "2024-01-23T15:51:41.257710",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predict Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b20a6ca7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T15:51:41.301142Z",
     "iopub.status.busy": "2024-01-23T15:51:41.300615Z",
     "iopub.status.idle": "2024-01-23T15:51:47.758446Z",
     "shell.execute_reply": "2024-01-23T15:51:47.757032Z"
    },
    "papermill": {
     "duration": 6.47729,
     "end_time": "2024-01-23T15:51:47.762181",
     "exception": false,
     "start_time": "2024-01-23T15:51:41.284891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "analyzer = MyAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e58a4749",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T15:51:47.794168Z",
     "iopub.status.busy": "2024-01-23T15:51:47.793765Z",
     "iopub.status.idle": "2024-01-23T16:14:21.855114Z",
     "shell.execute_reply": "2024-01-23T16:14:21.853659Z"
    },
    "papermill": {
     "duration": 1354.081693,
     "end_time": "2024-01-23T16:14:21.858624",
     "exception": false,
     "start_time": "2024-01-23T15:51:47.776931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tokens2index: 100%|██████████| 10189/10189 [00:09<00:00, 1069.73it/s]\n",
      "Analyzing entities: 100%|██████████| 10189/10189 [22:24<00:00,  7.58it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.run_on_train_data:\n",
    "    train_preds = analyzer.predict_tokens(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f687f6ee",
   "metadata": {
    "papermill": {
     "duration": 0.817145,
     "end_time": "2024-01-23T16:14:23.411440",
     "exception": false,
     "start_time": "2024-01-23T16:14:22.594295",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluate Performance on Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db91a09",
   "metadata": {
    "papermill": {
     "duration": 0.7185,
     "end_time": "2024-01-23T16:14:24.852115",
     "exception": false,
     "start_time": "2024-01-23T16:14:24.133615",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Generate Corresponding DataFrame for \"True\" Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a78975d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T16:14:26.367513Z",
     "iopub.status.busy": "2024-01-23T16:14:26.367017Z",
     "iopub.status.idle": "2024-01-23T16:14:28.043439Z",
     "shell.execute_reply": "2024-01-23T16:14:28.042087Z"
    },
    "papermill": {
     "duration": 2.404413,
     "end_time": "2024-01-23T16:14:28.046834",
     "exception": false,
     "start_time": "2024-01-23T16:14:25.642421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CONFIG.run_on_train_data:\n",
    "    train_act_records = []\n",
    "    count = 0\n",
    "    for entry in train_df:\n",
    "        for idx, (token, label) in enumerate(zip(entry[\"tokens\"], entry[\"labels\"])):\n",
    "            if label != 'O':\n",
    "                train_act_records.append({\n",
    "                    'row_id': count,\n",
    "                    'document': entry[\"document\"],\n",
    "                    'token': idx,\n",
    "                    'label': label,\n",
    "                })\n",
    "                count += 1\n",
    "\n",
    "    train_act = pd.DataFrame.from_records(train_act_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cd3162d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T16:14:29.537478Z",
     "iopub.status.busy": "2024-01-23T16:14:29.536630Z",
     "iopub.status.idle": "2024-01-23T16:14:29.542369Z",
     "shell.execute_reply": "2024-01-23T16:14:29.541369Z"
    },
    "papermill": {
     "duration": 0.737607,
     "end_time": "2024-01-23T16:14:29.544717",
     "exception": false,
     "start_time": "2024-01-23T16:14:28.807110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check that we haven't missed out any true values when making the \"train_act_records\"\n",
    "if CONFIG.run_on_train_data:\n",
    "    assert len(train_act) == sum(label_counts.values()) - label_counts['O'], \\\n",
    "        'mismatch between number of true labels in label_counts and train_act_records'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91054a35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T16:14:31.115397Z",
     "iopub.status.busy": "2024-01-23T16:14:31.114134Z",
     "iopub.status.idle": "2024-01-23T16:14:31.127840Z",
     "shell.execute_reply": "2024-01-23T16:14:31.126593Z"
    },
    "papermill": {
     "duration": 0.772248,
     "end_time": "2024-01-23T16:14:31.130972",
     "exception": false,
     "start_time": "2024-01-23T16:14:30.358724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pred_act_lists_for_dfs(preds: pd.DataFrame, act: pd.DataFrame):\n",
    "    document_idx_list = [(ex[\"document\"], len(ex[\"tokens\"])) for ex in train_df]\n",
    "    \n",
    "    preds_list = []\n",
    "    act_list = []\n",
    "    \n",
    "    for document, len_tokens in tqdm(document_idx_list, total=len(document_idx_list)):\n",
    "        preds_doc = preds[preds[\"document\"] == document].sort_values(by=\"token\")\n",
    "        act_doc = act[act[\"document\"] == document].sort_values(by=\"token\")\n",
    "        \n",
    "        # We do a \"merge\" (like in mergesort) to combine the results from the preds and \n",
    "        # actual values\n",
    "        preds_idx = 0\n",
    "        act_idx = 0\n",
    "        preds_list_sub = []\n",
    "        act_list_sub = []\n",
    "        for i in range(len_tokens):\n",
    "            preds_head, act_head = None, None\n",
    "            if preds_idx < len(preds_doc):\n",
    "                preds_head = preds_doc.iloc[preds_idx]\n",
    "            if act_idx < len(act_doc):\n",
    "                act_head = act_doc.iloc[act_idx]\n",
    "                \n",
    "            if act_head is not None and act_head[\"token\"] == i:\n",
    "                act_list_sub.append(act_head[\"label\"])\n",
    "                act_idx += 1\n",
    "            else:\n",
    "                act_list_sub.append('O')\n",
    "                \n",
    "            if preds_head is not None and preds_head[\"token\"] == i:\n",
    "                preds_list_sub.append(preds_head[\"label\"])\n",
    "                preds_idx += 1\n",
    "            else:\n",
    "                preds_list_sub.append('O')\n",
    "        \n",
    "        preds_list.extend(preds_list_sub)\n",
    "        act_list.extend(act_list_sub)\n",
    "            \n",
    "    return preds_list, act_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6dd94b1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T16:14:32.687007Z",
     "iopub.status.busy": "2024-01-23T16:14:32.686185Z",
     "iopub.status.idle": "2024-01-23T16:14:32.817403Z",
     "shell.execute_reply": "2024-01-23T16:14:32.815331Z"
    },
    "papermill": {
     "duration": 0.948247,
     "end_time": "2024-01-23T16:14:32.820522",
     "exception": false,
     "start_time": "2024-01-23T16:14:31.872275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PII micro F-beta score: 0.5043413570192693\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.run_on_train_data:\n",
    "    print(\"PII micro F-beta score:\", pii_fbeta_score(train_preds, train_act, beta = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "359f923a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T16:14:34.278840Z",
     "iopub.status.busy": "2024-01-23T16:14:34.277609Z",
     "iopub.status.idle": "2024-01-23T16:21:39.083373Z",
     "shell.execute_reply": "2024-01-23T16:21:39.081609Z"
    },
    "papermill": {
     "duration": 425.541615,
     "end_time": "2024-01-23T16:21:39.087919",
     "exception": false,
     "start_time": "2024-01-23T16:14:33.546304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10189/10189 [07:04<00:00, 23.99it/s]\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.run_on_train_data:\n",
    "    train_preds_list, train_act_list = get_pred_act_lists_for_dfs(train_preds, train_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30ba6947",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T16:21:41.294186Z",
     "iopub.status.busy": "2024-01-23T16:21:41.292677Z",
     "iopub.status.idle": "2024-01-23T16:21:41.653952Z",
     "shell.execute_reply": "2024-01-23T16:21:41.651841Z"
    },
    "papermill": {
     "duration": 1.5343,
     "end_time": "2024-01-23T16:21:41.657344",
     "exception": false,
     "start_time": "2024-01-23T16:21:40.123044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make sure that we processed the actual train list properly\n",
    "if CONFIG.run_on_train_data:\n",
    "    assert dict(Counter(train_act_list)) == label_counts, 'mismatch between label counts in label_counts and train_act_list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b664c78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T16:21:43.800065Z",
     "iopub.status.busy": "2024-01-23T16:21:43.799520Z",
     "iopub.status.idle": "2024-01-23T16:21:44.515433Z",
     "shell.execute_reply": "2024-01-23T16:21:44.512874Z"
    },
    "papermill": {
     "duration": 1.81589,
     "end_time": "2024-01-23T16:21:44.518294",
     "exception": false,
     "start_time": "2024-01-23T16:21:42.702404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Counter for predicted labels:\n",
      "-------------------------\n",
      "{'B-EMAIL': 2979,\n",
      " 'B-ID_NUM': 209,\n",
      " 'B-NAME_STUDENT': 15142,\n",
      " 'B-URL_PERSONAL': 214,\n",
      " 'I-NAME_STUDENT': 5725,\n",
      " 'I-URL_PERSONAL': 75,\n",
      " 'O': 5938972}\n",
      "\n",
      "-------------------------\n",
      "Counter for actual labels:\n",
      "-------------------------\n",
      "{'B-EMAIL': 2934,\n",
      " 'B-ID_NUM': 78,\n",
      " 'B-NAME_STUDENT': 9451,\n",
      " 'B-PHONE_NUM': 1861,\n",
      " 'B-STREET_ADDRESS': 2688,\n",
      " 'B-URL_PERSONAL': 110,\n",
      " 'B-USERNAME': 6,\n",
      " 'I-ID_NUM': 1,\n",
      " 'I-NAME_STUDENT': 5400,\n",
      " 'I-PHONE_NUM': 2616,\n",
      " 'I-STREET_ADDRESS': 6155,\n",
      " 'I-URL_PERSONAL': 1,\n",
      " 'O': 5932015}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.run_on_train_data:\n",
    "    print(\"-\"*25)\n",
    "    print(\"Counter for predicted labels:\")\n",
    "    print(\"-\"*25)\n",
    "    pprint.pprint(dict(Counter(train_preds_list)))\n",
    "    print()\n",
    "    \n",
    "    print(\"-\"*25)\n",
    "    print(\"Counter for actual labels:\")\n",
    "    print(\"-\"*25)\n",
    "    pprint.pprint(dict(Counter(train_act_list)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df637f5",
   "metadata": {
    "papermill": {
     "duration": 1.006505,
     "end_time": "2024-01-23T16:21:46.544796",
     "exception": false,
     "start_time": "2024-01-23T16:21:45.538291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Classification Report on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c224e51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T16:21:48.677354Z",
     "iopub.status.busy": "2024-01-23T16:21:48.676864Z",
     "iopub.status.idle": "2024-01-23T16:24:33.763605Z",
     "shell.execute_reply": "2024-01-23T16:24:33.762414Z"
    },
    "papermill": {
     "duration": 167.159283,
     "end_time": "2024-01-23T16:24:34.821227",
     "exception": false,
     "start_time": "2024-01-23T16:21:47.661944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "         B-EMAIL     0.9533    0.9389    0.9461      2979\n",
      "        B-ID_NUM     0.6795    0.2536    0.3693       209\n",
      "  B-NAME_STUDENT     0.8760    0.5468    0.6733     15142\n",
      "     B-PHONE_NUM     0.0000    0.0000    0.0000         0\n",
      "B-STREET_ADDRESS     0.0000    0.0000    0.0000         0\n",
      "  B-URL_PERSONAL     0.7364    0.3785    0.5000       214\n",
      "      B-USERNAME     0.0000    0.0000    0.0000         0\n",
      "        I-ID_NUM     0.0000    0.0000    0.0000         0\n",
      "  I-NAME_STUDENT     0.4670    0.4405    0.4534      5725\n",
      "     I-PHONE_NUM     0.0000    0.0000    0.0000         0\n",
      "I-STREET_ADDRESS     0.0000    0.0000    0.0000         0\n",
      "  I-URL_PERSONAL     0.0000    0.0000    0.0000        75\n",
      "               O     0.9983    0.9971    0.9977   5938972\n",
      "\n",
      "        accuracy                         0.9953   5963316\n",
      "       macro avg     0.3623    0.2735    0.3031   5963316\n",
      "    weighted avg     0.9974    0.9953    0.9963   5963316\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.run_on_train_data:\n",
    "    print(classification_report(train_preds_list, train_act_list, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65527ec0",
   "metadata": {
    "papermill": {
     "duration": 1.007627,
     "end_time": "2024-01-23T16:24:36.922142",
     "exception": false,
     "start_time": "2024-01-23T16:24:35.914515",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## F Beta Score on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4521d968",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T16:24:39.171694Z",
     "iopub.status.busy": "2024-01-23T16:24:39.169857Z",
     "iopub.status.idle": "2024-01-23T16:24:39.175899Z",
     "shell.execute_reply": "2024-01-23T16:24:39.174806Z"
    },
    "papermill": {
     "duration": 1.201132,
     "end_time": "2024-01-23T16:24:39.178315",
     "exception": false,
     "start_time": "2024-01-23T16:24:37.977183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if CONFIG.run_on_train_data:\n",
    "#     print(\"Micro F1 Beta Score:\", score(train_preds_list, train_act_list))\n",
    "#     print(\"Macro F1 Beta Score:\", macro_score(train_preds_list, train_act_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf30dbf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T16:24:41.409063Z",
     "iopub.status.busy": "2024-01-23T16:24:41.408643Z",
     "iopub.status.idle": "2024-01-23T16:24:42.063391Z",
     "shell.execute_reply": "2024-01-23T16:24:42.061147Z"
    },
    "papermill": {
     "duration": 1.864892,
     "end_time": "2024-01-23T16:24:42.066530",
     "exception": false,
     "start_time": "2024-01-23T16:24:40.201638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CONFIG.run_on_train_data:\n",
    "    del train_preds_list, train_act_list, train_preds, train_act\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fd1ebf",
   "metadata": {
    "papermill": {
     "duration": 1.096799,
     "end_time": "2024-01-23T16:24:44.165731",
     "exception": false,
     "start_time": "2024-01-23T16:24:43.068932",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predict Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "882a0813",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T16:24:46.183124Z",
     "iopub.status.busy": "2024-01-23T16:24:46.182139Z",
     "iopub.status.idle": "2024-01-23T16:24:48.037571Z",
     "shell.execute_reply": "2024-01-23T16:24:48.036208Z"
    },
    "papermill": {
     "duration": 2.860567,
     "end_time": "2024-01-23T16:24:48.040506",
     "exception": false,
     "start_time": "2024-01-23T16:24:45.179939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tokens2index: 100%|██████████| 10/10 [00:00<00:00, 612.73it/s]\n",
      "Analyzing entities: 100%|██████████| 10/10 [00:01<00:00,  5.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>document</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>55</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  document  token           label\n",
       "0      0         7      9  B-NAME_STUDENT\n",
       "1      1         7     10  I-NAME_STUDENT\n",
       "2      2         7     52  B-NAME_STUDENT\n",
       "3      3         7     53  I-NAME_STUDENT\n",
       "4      4         7     55  B-NAME_STUDENT"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = analyzer.predict_tokens(test_df)\n",
    "test_preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af6dc90",
   "metadata": {
    "papermill": {
     "duration": 1.07426,
     "end_time": "2024-01-23T16:24:50.115400",
     "exception": false,
     "start_time": "2024-01-23T16:24:49.041140",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f3df089",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T16:24:52.263534Z",
     "iopub.status.busy": "2024-01-23T16:24:52.262538Z",
     "iopub.status.idle": "2024-01-23T16:24:52.281919Z",
     "shell.execute_reply": "2024-01-23T16:24:52.280895Z"
    },
    "papermill": {
     "duration": 1.122342,
     "end_time": "2024-01-23T16:24:52.284408",
     "exception": false,
     "start_time": "2024-01-23T16:24:51.162066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>document</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>55</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  document  token           label\n",
       "0       0         7      9  B-NAME_STUDENT\n",
       "1       1         7     10  I-NAME_STUDENT\n",
       "2       2         7     52  B-NAME_STUDENT\n",
       "3       3         7     53  I-NAME_STUDENT\n",
       "4       4         7     55  B-NAME_STUDENT"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(test_preds)\n",
    "submission.columns = ['row_id','document', 'token', 'label']\n",
    "submission.to_csv('submission.csv', index = False)\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7500999,
     "sourceId": 66653,
     "sourceType": "competition"
    },
    {
     "datasetId": 4332496,
     "sourceId": 7443360,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 159367535,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2044.772889,
   "end_time": "2024-01-23T16:24:56.554719",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-23T15:50:51.781830",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
