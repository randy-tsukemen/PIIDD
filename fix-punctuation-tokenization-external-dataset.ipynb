{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55b239f7",
   "metadata": {
    "papermill": {
     "duration": 0.017072,
     "end_time": "2024-02-16T14:07:40.973745",
     "exception": false,
     "start_time": "2024-02-16T14:07:40.956673",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Remarks\n",
    "\n",
    "THANK YOU FOR ALL THE UPVOTES!\n",
    "\n",
    "- This notebook was purely created to assist Moth in fixing the tokenization with punctuation for https://www.kaggle.com/datasets/alejopaullier/pii-external-dataset/data?select=pii_dataset.csv\n",
    "- This notebook was expanded to also reformat the dataset by PJMathematician: https://www.kaggle.com/datasets/pjmathematician/pii-detection-dataset-gpt\n",
    "\n",
    "- As you can see in version numbers, I went to several versions to try to get these in the correct format - if you see any mistakes, please reach out!\n",
    "\n",
    "- Thank you to Raja for creating this application, which helps finding mistakes relatively fast: https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data/discussion/475646#2645266"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6423085",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:07:41.006637Z",
     "iopub.status.busy": "2024-02-16T14:07:41.005863Z",
     "iopub.status.idle": "2024-02-16T14:07:42.045973Z",
     "shell.execute_reply": "2024-02-16T14:07:42.044650Z"
    },
    "papermill": {
     "duration": 1.060057,
     "end_time": "2024-02-16T14:07:42.049066",
     "exception": false,
     "start_time": "2024-02-16T14:07:40.989009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import string\n",
    "from Levenshtein import distance as le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cb7e598",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:07:42.087041Z",
     "iopub.status.busy": "2024-02-16T14:07:42.086488Z",
     "iopub.status.idle": "2024-02-16T14:07:48.470950Z",
     "shell.execute_reply": "2024-02-16T14:07:48.469785Z"
    },
    "papermill": {
     "duration": 6.405896,
     "end_time": "2024-02-16T14:07:48.473822",
     "exception": false,
     "start_time": "2024-02-16T14:07:42.067926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "en_tokenizer = English().tokenizer\n",
    "\n",
    "def tokenize_with_spacy(text, tokenizer=en_tokenizer):\n",
    "    tokenized_text = tokenizer(text)\n",
    "    tokens = [token.text for token in tokenized_text]\n",
    "    trailing_whitespace = [bool(token.whitespace_) for token in tokenized_text]\n",
    "    return {'tokens': tokens, 'trailing_whitespace': trailing_whitespace}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44e525e5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-02-16T14:07:48.507607Z",
     "iopub.status.busy": "2024-02-16T14:07:48.506321Z",
     "iopub.status.idle": "2024-02-16T14:07:59.440305Z",
     "shell.execute_reply": "2024-02-16T14:07:59.439154Z"
    },
    "papermill": {
     "duration": 10.953483,
     "end_time": "2024-02-16T14:07:59.443027",
     "exception": false,
     "start_time": "2024-02-16T14:07:48.489544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4434, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ = pd.read_csv(\"/kaggle/input/pii-external-dataset/pii_dataset.csv\")\n",
    "# the columns contain string representations of lists - we can eval them to turn them to lists\n",
    "new_[\"tokens\"] = new_.tokens.apply(lambda x: ast.literal_eval(x))\n",
    "new_[\"trailing_whitespace\"] = new_.trailing_whitespace.apply(\n",
    "    lambda x: ast.literal_eval(x)\n",
    ")\n",
    "new_[\"labels\"] = new_.labels.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# unprocessed versions for comparison later\n",
    "og=new_.copy(deep=True)\n",
    "ex = new_.explode([\"tokens\",\"trailing_whitespace\",\"labels\"])\n",
    "\n",
    "new_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8472b77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:07:59.476617Z",
     "iopub.status.busy": "2024-02-16T14:07:59.476177Z",
     "iopub.status.idle": "2024-02-16T14:07:59.480752Z",
     "shell.execute_reply": "2024-02-16T14:07:59.479613Z"
    },
    "papermill": {
     "duration": 0.024679,
     "end_time": "2024-02-16T14:07:59.483222",
     "exception": false,
     "start_time": "2024-02-16T14:07:59.458543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# moth check: Masako Mitsubishi NAME_STUDENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18ba94e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:07:59.516393Z",
     "iopub.status.busy": "2024-02-16T14:07:59.515972Z",
     "iopub.status.idle": "2024-02-16T14:07:59.522778Z",
     "shell.execute_reply": "2024-02-16T14:07:59.521378Z"
    },
    "papermill": {
     "duration": 0.026673,
     "end_time": "2024-02-16T14:07:59.525385",
     "exception": false,
     "start_time": "2024-02-16T14:07:59.498712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_map={\n",
    "    \"O\":\"O\",\n",
    "    \"B-NAME_STUDENT\":\"NAME_STUDENT\",\n",
    "    \"I-NAME_STUDENT\":\"NAME_STUDENT\",\n",
    "    \"B-URL_PERSONAL\":\"URL_PERSONAL\",\n",
    "    \"I-URL_PERSONAL\":\"URL_PERSONAL\",\n",
    "    \"B-EMAIL\":\"EMAIL\",\n",
    "    \"I-EMAIL\":\"EMAIL\",\n",
    "    \"B-ID_NUM\":\"ID_NUM\",\n",
    "    \"I-ID_NUM\":\"ID_NUM\",\n",
    "    \"B-USERNAME\":\"USERNAME\",\n",
    "    \"I-USERNAME\":\"USERNAME\",\n",
    "    \"B-PHONE_NUM\":\"PHONE_NUM\",\n",
    "    \"I-PHONE_NUM\":\"PHONE_NUM\",\n",
    "    \"B-STREET_ADDRESS\":\"STREET_ADDRESS\",\n",
    "    \"I-STREET_ADDRESS\":\"STREET_ADDRESS\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "987b8a83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:07:59.557945Z",
     "iopub.status.busy": "2024-02-16T14:07:59.557567Z",
     "iopub.status.idle": "2024-02-16T14:07:59.587117Z",
     "shell.execute_reply": "2024-02-16T14:07:59.586273Z"
    },
    "papermill": {
     "duration": 0.048803,
     "end_time": "2024-02-16T14:07:59.589571",
     "exception": false,
     "start_time": "2024-02-16T14:07:59.540768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "      <th>labels</th>\n",
       "      <th>prompt</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>phone</th>\n",
       "      <th>job</th>\n",
       "      <th>address</th>\n",
       "      <th>username</th>\n",
       "      <th>url</th>\n",
       "      <th>hobby</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>45507bc9-7b42-49fd-8fa3-031cdaade706</td>\n",
       "      <td>In the bustling city of Alexandria, amidst the...</td>\n",
       "      <td>[In, the, bustling, city, of, Alexandria,, ami...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, B-NAME...</td>\n",
       "      <td>\\n    Write a fictional semi-formal biography ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Shankar Yu</td>\n",
       "      <td>shankar-yu@outlook.net</td>\n",
       "      <td>(13) 98824-5547</td>\n",
       "      <td>attorney</td>\n",
       "      <td>5036 Jericho Street</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mixology</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                document  \\\n",
       "10  45507bc9-7b42-49fd-8fa3-031cdaade706   \n",
       "\n",
       "                                                 text  \\\n",
       "10  In the bustling city of Alexandria, amidst the...   \n",
       "\n",
       "                                               tokens  \\\n",
       "10  [In, the, bustling, city, of, Alexandria,, ami...   \n",
       "\n",
       "                                  trailing_whitespace  \\\n",
       "10  [True, True, True, True, True, True, True, Tru...   \n",
       "\n",
       "                                               labels  \\\n",
       "10  [O, O, O, O, O, O, O, O, O, O, O, O, O, B-NAME...   \n",
       "\n",
       "                                               prompt  prompt_id        name  \\\n",
       "10  \\n    Write a fictional semi-formal biography ...          0  Shankar Yu   \n",
       "\n",
       "                     email            phone       job              address  \\\n",
       "10  shankar-yu@outlook.net  (13) 98824-5547  attorney  5036 Jericho Street   \n",
       "\n",
       "   username  url     hobby  len  \n",
       "10      NaN  NaN  Mixology  347  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_[new_.document.str.contains(\"45507\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9046735d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:07:59.624284Z",
     "iopub.status.busy": "2024-02-16T14:07:59.623827Z",
     "iopub.status.idle": "2024-02-16T14:07:59.635455Z",
     "shell.execute_reply": "2024-02-16T14:07:59.634296Z"
    },
    "papermill": {
     "duration": 0.032569,
     "end_time": "2024-02-16T14:07:59.638590",
     "exception": false,
     "start_time": "2024-02-16T14:07:59.606021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the bustling city of Alexandria, amidst the clamor of daily life, I, Shankar Yu, emerged into this world, blessed with an unyielding spirit and a profound curiosity that would shape my destiny. From my humble beginnings at 5036 Jericho Street, I embarked on a journey that would propel me to new heights, leaving an indelible mark on the tapestry of human endeavor. The call of knowledge resonated within me from a tender age. I spent countless hours poring over books, devouring every morsel of information that came my way. The allure of the unknown beckoned me forth, igniting a passion for exploration and discovery that would never wane. As fate would have it, my path intersected with a group of kindred spirits, fellow seekers of truth and enlightenment. Together, we embarked on a quest for answers, traversing the globe in search of ancient wisdom and hidden knowledge. Our journey took us to remote corners of the world, where we encountered diverse cultures and traditions, each offering a unique perspective on the human experience. Through my travels, I encountered challenges that tested the limits of my endurance and resolve. I faced adversity with unwavering determination, refusing to succumb to despair. Each obstacle I overcame strengthened my spirit and deepened my understanding of the human condition. Along my path, I encountered remarkable individuals who imparted invaluable lessons and shaped my worldview. Their wisdom and guidance inspired me to pursue my dreams with renewed vigor, to strive for excellence in all my endeavors. I am eternally grateful for the opportunities that have come my way, for the experiences that have molded me into the person I am today. As I continue my journey through life, I am filled with a sense of purpose and an unwavering belief in the power of human potential. With every step I take, I carry with me the memories and lessons of the past, the hopes and dreams of the future. My name is Shankar Yu, and this is my story. Contact Information: Phone Number: (13) 98824-5547 Email Address: shankar-yu@outlook.net Address: 5036 Jericho Street\n"
     ]
    }
   ],
   "source": [
    "print(new_[new_.document.str.contains(\"45507\")].text.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b6c294d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:07:59.672146Z",
     "iopub.status.busy": "2024-02-16T14:07:59.671774Z",
     "iopub.status.idle": "2024-02-16T14:08:02.547507Z",
     "shell.execute_reply": "2024-02-16T14:08:02.546313Z"
    },
    "papermill": {
     "duration": 2.896442,
     "end_time": "2024-02-16T14:08:02.550855",
     "exception": false,
     "start_time": "2024-02-16T14:07:59.654413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_labels_pj_format(row):\n",
    "    # wanted format: {\"NAME_STUDENT\":[\"Valentin\", \"Werner\"]}\n",
    "    labeldict={}\n",
    "    labels_ = [label_map[l] for l in row[\"labels\"]]\n",
    "    tokens_ = row[\"tokens\"]\n",
    "    for t, l in zip(tokens_, labels_):\n",
    "        # we do not need to collect O-Labels\n",
    "        if l!=\"O\":\n",
    "            # append to list if already existent\n",
    "            if l in labeldict.keys():\n",
    "                # remove tailing punctuation if exists (this is copied from my old approach)\n",
    "                while t[-1] in string.punctuation: \n",
    "                    t=t[:-1]\n",
    "                labeldict[l] += [t]\n",
    "            \n",
    "            # create new list if not already existent\n",
    "            else:\n",
    "                # remove tailing punctuation if exists (this is copied from my old approach)\n",
    "                while t[-1] in string.punctuation: \n",
    "                    t=t[:-1]\n",
    "                labeldict[l] = [t]\n",
    "    return labeldict\n",
    "\n",
    "def pj_to_pj(label_in):\n",
    "    labeldict={}\n",
    "    for label, pii, in label_in.items():\n",
    "        pii_list=[]\n",
    "        for info in pii:\n",
    "            pii_list += tokenize_with_spacy(info)[\"tokens\"]\n",
    "        clean_pii_list=[]\n",
    "        for token in pii_list:\n",
    "            # this string.punctuation filters everything except \"(\" which might be an opening token in phone numbers\n",
    "            while len(token) > 0 and token[-1] in \"\".join(string.punctuation.split(\"(\")): \n",
    "                token=token[:-1]\n",
    "            if len(token) > 0:\n",
    "                clean_pii_list+=[token]\n",
    "        labeldict[label] = clean_pii_list\n",
    "    return labeldict\n",
    "\n",
    "labels_=[]\n",
    "for i, row in new_.iterrows():\n",
    "    labeldict=get_labels_pj_format(row)\n",
    "    labeldict=pj_to_pj(labeldict)\n",
    "    labels_.append(labeldict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20121cbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:02.584967Z",
     "iopub.status.busy": "2024-02-16T14:08:02.584571Z",
     "iopub.status.idle": "2024-02-16T14:08:02.592679Z",
     "shell.execute_reply": "2024-02-16T14:08:02.591582Z"
    },
    "papermill": {
     "duration": 0.027945,
     "end_time": "2024-02-16T14:08:02.595018",
     "exception": false,
     "start_time": "2024-02-16T14:08:02.567073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NAME_STUDENT': ['Shankar', 'Yu', 'Shankar', 'Yu'],\n",
       " 'STREET_ADDRESS': ['5036', 'Jericho', 'Street', '5036', 'Jericho', 'Street'],\n",
       " 'PHONE_NUM': ['(', '13', '98824', '5547'],\n",
       " 'EMAIL': ['shankar-yu@outlook.net']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28249681",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:02.631525Z",
     "iopub.status.busy": "2024-02-16T14:08:02.631133Z",
     "iopub.status.idle": "2024-02-16T14:08:02.657339Z",
     "shell.execute_reply": "2024-02-16T14:08:02.656343Z"
    },
    "papermill": {
     "duration": 0.047964,
     "end_time": "2024-02-16T14:08:02.659688",
     "exception": false,
     "start_time": "2024-02-16T14:08:02.611724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "      <th>labels</th>\n",
       "      <th>prompt</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>phone</th>\n",
       "      <th>job</th>\n",
       "      <th>address</th>\n",
       "      <th>username</th>\n",
       "      <th>url</th>\n",
       "      <th>hobby</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3436</th>\n",
       "      <td>f0fd1c48-cee0-4c40-92b1-9ea3be46d7e5</td>\n",
       "      <td>Homer Pavlov, a seasoned businessman known for...</td>\n",
       "      <td>[Homer, Pavlov,, a, seasoned, businessman, kno...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>[B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...</td>\n",
       "      <td>\\n    Homer Pavlov is a businessman. Write abo...</td>\n",
       "      <td>2</td>\n",
       "      <td>Homer Pavlov</td>\n",
       "      <td>homer_pavlov7000@msn.gov</td>\n",
       "      <td>(562) 527-6711</td>\n",
       "      <td>businessman</td>\n",
       "      <td>811 River Dell Drive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gymnastics</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  document  \\\n",
       "3436  f0fd1c48-cee0-4c40-92b1-9ea3be46d7e5   \n",
       "\n",
       "                                                   text  \\\n",
       "3436  Homer Pavlov, a seasoned businessman known for...   \n",
       "\n",
       "                                                 tokens  \\\n",
       "3436  [Homer, Pavlov,, a, seasoned, businessman, kno...   \n",
       "\n",
       "                                    trailing_whitespace  \\\n",
       "3436  [True, True, True, True, True, True, True, Tru...   \n",
       "\n",
       "                                                 labels  \\\n",
       "3436  [B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...   \n",
       "\n",
       "                                                 prompt  prompt_id  \\\n",
       "3436  \\n    Homer Pavlov is a businessman. Write abo...          2   \n",
       "\n",
       "              name                     email           phone          job  \\\n",
       "3436  Homer Pavlov  homer_pavlov7000@msn.gov  (562) 527-6711  businessman   \n",
       "\n",
       "                   address username  url       hobby  len  \n",
       "3436  811 River Dell Drive      NaN  NaN  Gymnastics  371  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_[new_.document==\"f0fd1c48-cee0-4c40-92b1-9ea3be46d7e5\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f5dc76",
   "metadata": {
    "papermill": {
     "duration": 0.016444,
     "end_time": "2024-02-16T14:08:02.756767",
     "exception": false,
     "start_time": "2024-02-16T14:08:02.740323",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Retokenize with spacy\n",
    "- This gets the tokens in the exact format wanted by the challenge providers, however, this may cause a mismatch of labels before and after tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe9b69fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:02.791054Z",
     "iopub.status.busy": "2024-02-16T14:08:02.790660Z",
     "iopub.status.idle": "2024-02-16T14:08:12.445788Z",
     "shell.execute_reply": "2024-02-16T14:08:12.444536Z"
    },
    "papermill": {
     "duration": 9.675816,
     "end_time": "2024-02-16T14:08:12.448854",
     "exception": false,
     "start_time": "2024-02-16T14:08:02.773038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['tokens', 'trailing_whitespace'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [tokenize_with_spacy(r[\"text\"]) for idx, r in new_.iterrows()]\n",
    "tokens[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec2c645",
   "metadata": {
    "papermill": {
     "duration": 0.016534,
     "end_time": "2024-02-16T14:08:12.482666",
     "exception": false,
     "start_time": "2024-02-16T14:08:12.466132",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Re-assemble labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbe785af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:12.517850Z",
     "iopub.status.busy": "2024-02-16T14:08:12.517429Z",
     "iopub.status.idle": "2024-02-16T14:08:14.256614Z",
     "shell.execute_reply": "2024-02-16T14:08:14.255409Z"
    },
    "papermill": {
     "duration": 1.760294,
     "end_time": "2024-02-16T14:08:14.259488",
     "exception": false,
     "start_time": "2024-02-16T14:08:12.499194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This loop is very inefficient, but it takes 0.3 seconds - so who cares\n",
    "\n",
    "new_=[]\n",
    "for tok, l in zip(tokens, labels_):\n",
    "    \n",
    "    # these will just be forwarded to the final result, as we do not change these\n",
    "    t = tok[\"tokens\"]\n",
    "    ws = tok[\"trailing_whitespace\"]\n",
    "    \n",
    "    # Create \"O\" label as standard value to overwrite on specific indices\n",
    "    new_labels=[\"O\"]*len(t)\n",
    "    \n",
    "    # Find entities from labels_ in the text\n",
    "    for ent_type, ent_list in l.items():\n",
    "        for ent_ in ent_list:\n",
    "            # find occurence of tagged entities in the list\n",
    "            # - this assumes that entities are not containing commong words such as \"the\"\n",
    "            indices = [i for i, x in enumerate(t) if x == ent_]\n",
    "            for i in indices:\n",
    "                # overwrite \"O\" label with correct label\n",
    "                new_labels[i] = ent_type\n",
    "    new_.append({\"tokens\":t, \"trailing_whitespace\":ws, \"labels\":new_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "925b117b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:14.296668Z",
     "iopub.status.busy": "2024-02-16T14:08:14.296179Z",
     "iopub.status.idle": "2024-02-16T14:08:17.460968Z",
     "shell.execute_reply": "2024-02-16T14:08:17.459685Z"
    },
    "papermill": {
     "duration": 3.186466,
     "end_time": "2024-02-16T14:08:17.463811",
     "exception": false,
     "start_time": "2024-02-16T14:08:14.277345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# As we only labelled words, but not punctuation inbetween these words, we need to fill the gaps\n",
    "new_2=[]\n",
    "punctuation = [p for p in string.punctuation]\n",
    "for r, labeldict in zip(new_, labels_):\n",
    "    \n",
    "    sandwich_on_comma = [\"STREET_ADDRESS\"]\n",
    "    # again these are just forwarded\n",
    "    t = r[\"tokens\"]\n",
    "    ws = r[\"trailing_whitespace\"]\n",
    "    # again, these may get overwritten\n",
    "    label = r[\"labels\"]\n",
    "    new_labels=[\"O\"]*len(label)\n",
    "    for i, l in enumerate(label):\n",
    "        # get prior label if possible\n",
    "        if i != 0: prior_label=label[i-1]\n",
    "        else: prior_label=\"O\"\n",
    "\n",
    "        # get next label\n",
    "        if i+1 < len(label): next_label=label[i+1]\n",
    "        elif i+1 == len(label): next_label=\"O\"\n",
    "        \n",
    "        # skip filler / list words that split multiple entities\n",
    "        if (t[i] == \"and\" and l == \"O\") or (t[i] == \"or\" and l == \"O\"):\n",
    "            new_labels[i] = \"O\"\n",
    "        elif (t[i] == \".\" and l == \"O\" and prior_label==\"NAME_STUDENT\"):\n",
    "            new_labels[i] = \"O\"\n",
    "        # \"(\" might be labeled as phone num, which is only correct if more phone num follows\n",
    "        elif t[i] == \"(\" and l == \"PHONE_NUM\" and next_label!=\"PHONE_NUM\":\n",
    "            new_labels[i] = \"O\"\n",
    "        elif t[i] == \"(\" and l != \"PHONE_NUM\":\n",
    "            # print(l, t[i], t[i+1]) # this is whenever we have something like \"my name is Valentin (Valle)\"\n",
    "            new_labels[i] = \"O\"\n",
    "        elif prior_label == \"EMAIL\" and t[i] == \"to\":\n",
    "            new_labels[i] = \"O\"\n",
    "        elif (prior_label == \"NAME_STUDENT\" or prior_label == \"O\") and t[i] == \"'s\":\n",
    "            new_labels[i] = \"O\"\n",
    "            \n",
    "        # only street addresses should contain commas - this avoids labelling sandwiches\n",
    "        # which chain multiple entities, such as \"Valentin Werner, Thomas Müller, and Manuel Neuer\"\n",
    "        # As these should be three separate entities\n",
    "        elif t[i] == \",\" and prior_label not in sandwich_on_comma:\n",
    "            new_labels[i] = \"O\"\n",
    "            \n",
    "        # replace if we got a sandwich (\"LABEL\"-\"O\"-\"LABEL\", such as \"Berlin\" - \",\" - \"Germany\")\n",
    "        elif prior_label == next_label and prior_label != \"O\":\n",
    "            new_labels[i] = prior_label\n",
    "        elif l != \"O\":\n",
    "            new_labels[i] = l\n",
    "        else:\n",
    "            new_labels[i] = \"O\"\n",
    "    \n",
    "    new_2.append({\"tokens\":t, \"trailing_whitespace\":ws, \"labels\":new_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6275023e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:17.501866Z",
     "iopub.status.busy": "2024-02-16T14:08:17.501418Z",
     "iopub.status.idle": "2024-02-16T14:08:18.181089Z",
     "shell.execute_reply": "2024-02-16T14:08:18.179837Z"
    },
    "papermill": {
     "duration": 0.702399,
     "end_time": "2024-02-16T14:08:18.184118",
     "exception": false,
     "start_time": "2024-02-16T14:08:17.481719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Turn labels into BIO Labels\n",
    "new_bio=[]\n",
    "for i, r in enumerate(new_2):\n",
    "    \n",
    "    # again, these are just forwarded\n",
    "    t = r[\"tokens\"]\n",
    "    ws = r[\"trailing_whitespace\"]\n",
    "    # again, these might get overwritten\n",
    "    label = r[\"labels\"]\n",
    "\n",
    "    # keep track of last label to identify when to use B or I\n",
    "    last_label=\"O\"\n",
    "    for i, l in enumerate(label):\n",
    "        if l != last_label and l != \"O\":\n",
    "            label[i] = \"B-\"+l\n",
    "        elif l == last_label and last_label != \"O\":\n",
    "            label[i] = \"I-\"+l\n",
    "        last_label = l\n",
    "    new_bio.append({\"doc_prelim\":i,\"tokens\":t, \"trailing_whitespace\":ws, \"labels\":label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9de904c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:18.221546Z",
     "iopub.status.busy": "2024-02-16T14:08:18.220745Z",
     "iopub.status.idle": "2024-02-16T14:08:18.646001Z",
     "shell.execute_reply": "2024-02-16T14:08:18.645015Z"
    },
    "papermill": {
     "duration": 0.446847,
     "end_time": "2024-02-16T14:08:18.648752",
     "exception": false,
     "start_time": "2024-02-16T14:08:18.201905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1570222, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ = pd.DataFrame(new_bio)\n",
    "new_ = new_.explode([\"tokens\", \"trailing_whitespace\", \"labels\"])\n",
    "new_.shape # note that this produces even more tokens than my prior approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09df36da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:18.685277Z",
     "iopub.status.busy": "2024-02-16T14:08:18.684214Z",
     "iopub.status.idle": "2024-02-16T14:08:18.700393Z",
     "shell.execute_reply": "2024-02-16T14:08:18.699264Z"
    },
    "papermill": {
     "duration": 0.036975,
     "end_time": "2024-02-16T14:08:18.703153",
     "exception": false,
     "start_time": "2024-02-16T14:08:18.666178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_prelim</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>My</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>name</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>is</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>Aaliyah</td>\n",
       "      <td>True</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>Popova</td>\n",
       "      <td>False</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>,</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>and</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>I</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>am</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>a</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>jeweler</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>with</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>years</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>of</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>experience</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>.</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>I</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>remember</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>a</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>very</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>unique</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>and</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>challenging</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>410</td>\n",
       "      <td>project</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_prelim       tokens trailing_whitespace          labels\n",
       "0         410           My                True               O\n",
       "0         410         name                True               O\n",
       "0         410           is                True               O\n",
       "0         410      Aaliyah                True  B-NAME_STUDENT\n",
       "0         410       Popova               False  I-NAME_STUDENT\n",
       "0         410            ,                True               O\n",
       "0         410          and                True               O\n",
       "0         410            I                True               O\n",
       "0         410           am                True               O\n",
       "0         410            a                True               O\n",
       "0         410      jeweler                True               O\n",
       "0         410         with                True               O\n",
       "0         410           13                True               O\n",
       "0         410        years                True               O\n",
       "0         410           of                True               O\n",
       "0         410   experience               False               O\n",
       "0         410            .                True               O\n",
       "0         410            I                True               O\n",
       "0         410     remember                True               O\n",
       "0         410            a                True               O\n",
       "0         410         very                True               O\n",
       "0         410       unique                True               O\n",
       "0         410          and                True               O\n",
       "0         410  challenging                True               O\n",
       "0         410      project                True               O"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "501c5678",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:18.743442Z",
     "iopub.status.busy": "2024-02-16T14:08:18.742753Z",
     "iopub.status.idle": "2024-02-16T14:08:19.257527Z",
     "shell.execute_reply": "2024-02-16T14:08:19.256313Z"
    },
    "papermill": {
     "duration": 0.538702,
     "end_time": "2024-02-16T14:08:19.260383",
     "exception": false,
     "start_time": "2024-02-16T14:08:18.721681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add doc id and text\n",
    "new_ = pd.merge(new_.reset_index(names=\"doc_\"), og.reset_index(names=\"doc_\")[[\"doc_\",\"document\",\"text\"]], on=\"doc_\", how=\"left\").drop(columns=[\"doc_\",\"doc_prelim\"])\n",
    "# reorder columns to logical order\n",
    "new_ = new_[[\"document\",\"text\",\"tokens\",\"trailing_whitespace\",\"labels\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89def14a",
   "metadata": {
    "papermill": {
     "duration": 0.017365,
     "end_time": "2024-02-16T14:08:19.294957",
     "exception": false,
     "start_time": "2024-02-16T14:08:19.277592",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sanity checks\n",
    "- Same amount of labels\n",
    "- Does the amount of extra tokens add up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93bfc27f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:19.331355Z",
     "iopub.status.busy": "2024-02-16T14:08:19.330609Z",
     "iopub.status.idle": "2024-02-16T14:08:20.402256Z",
     "shell.execute_reply": "2024-02-16T14:08:20.401017Z"
    },
    "papermill": {
     "duration": 1.092783,
     "end_time": "2024-02-16T14:08:20.404859",
     "exception": false,
     "start_time": "2024-02-16T14:08:19.312076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169854</th>\n",
       "      <td>6716411b-4770-4945-bb6c-05c963f984f8</td>\n",
       "      <td>Yukio Ma is an experienced electrical engineer...</td>\n",
       "      <td>)</td>\n",
       "      <td>True</td>\n",
       "      <td>I-STREET_ADDRESS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    document  \\\n",
       "169854  6716411b-4770-4945-bb6c-05c963f984f8   \n",
       "\n",
       "                                                     text tokens  \\\n",
       "169854  Yukio Ma is an experienced electrical engineer...      )   \n",
       "\n",
       "       trailing_whitespace            labels  \n",
       "169854                True  I-STREET_ADDRESS  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_[(new_.tokens.str.contains(\"\\)\")) & ~(new_.labels.isin([\"I-PHONE_NUM\",\"O\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7b4758d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:20.442150Z",
     "iopub.status.busy": "2024-02-16T14:08:20.441737Z",
     "iopub.status.idle": "2024-02-16T14:08:20.611391Z",
     "shell.execute_reply": "2024-02-16T14:08:20.610055Z"
    },
    "papermill": {
     "duration": 0.191756,
     "end_time": "2024-02-16T14:08:20.614290",
     "exception": false,
     "start_time": "2024-02-16T14:08:20.422534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new shape:  1570222 - old shape + punctuation:  1544255\n"
     ]
    }
   ],
   "source": [
    "# Since we only check for punctuation, this looks fine to me with some ratio of spacy tokenization patterns that are not punctuation\n",
    "print(\n",
    "    \"new shape: \", \n",
    "    new_.shape[0], \n",
    "    \"- old shape + punctuation: \", \n",
    "    ex.shape[0] + new_[(new_.tokens.isin([p for p in string.punctuation]))].shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02fc9294",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:20.652589Z",
     "iopub.status.busy": "2024-02-16T14:08:20.651844Z",
     "iopub.status.idle": "2024-02-16T14:08:20.680867Z",
     "shell.execute_reply": "2024-02-16T14:08:20.679582Z"
    },
    "papermill": {
     "duration": 0.051029,
     "end_time": "2024-02-16T14:08:20.683484",
     "exception": false,
     "start_time": "2024-02-16T14:08:20.632455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "      <th>labels</th>\n",
       "      <th>prompt</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>phone</th>\n",
       "      <th>job</th>\n",
       "      <th>address</th>\n",
       "      <th>username</th>\n",
       "      <th>url</th>\n",
       "      <th>hobby</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>3e47e235-6526-4555-875b-c908499e5d33</td>\n",
       "      <td>My name is Gabriel Fischer. I'm a plumber, and...</td>\n",
       "      <td>[My, name, is, Gabriel, Fischer., I'm, a, plum...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "      <td>[O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O, O...</td>\n",
       "      <td>\\n    Gabriel Fischer is a plumber. Write a fi...</td>\n",
       "      <td>3</td>\n",
       "      <td>Gabriel Fischer</td>\n",
       "      <td>gabriel.fischer@gmail.org</td>\n",
       "      <td>+27 67 568 4444</td>\n",
       "      <td>plumber</td>\n",
       "      <td>1636 Briarview Court</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wood burning</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 document  \\\n",
       "216  3e47e235-6526-4555-875b-c908499e5d33   \n",
       "\n",
       "                                                  text  \\\n",
       "216  My name is Gabriel Fischer. I'm a plumber, and...   \n",
       "\n",
       "                                                tokens  \\\n",
       "216  [My, name, is, Gabriel, Fischer., I'm, a, plum...   \n",
       "\n",
       "                                   trailing_whitespace  \\\n",
       "216  [True, True, True, True, True, True, True, Tru...   \n",
       "\n",
       "                                                labels  \\\n",
       "216  [O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O, O...   \n",
       "\n",
       "                                                prompt  prompt_id  \\\n",
       "216  \\n    Gabriel Fischer is a plumber. Write a fi...          3   \n",
       "\n",
       "                name                      email            phone      job  \\\n",
       "216  Gabriel Fischer  gabriel.fischer@gmail.org  +27 67 568 4444  plumber   \n",
       "\n",
       "                  address username  url         hobby  len  \n",
       "216  1636 Briarview Court      NaN  NaN  Wood burning  259  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og[og.document==\"3e47e235-6526-4555-875b-c908499e5d33\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b86d9bc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:20.725447Z",
     "iopub.status.busy": "2024-02-16T14:08:20.724749Z",
     "iopub.status.idle": "2024-02-16T14:08:20.732602Z",
     "shell.execute_reply": "2024-02-16T14:08:20.731653Z"
    },
    "papermill": {
     "duration": 0.034863,
     "end_time": "2024-02-16T14:08:20.736930",
     "exception": false,
     "start_time": "2024-02-16T14:08:20.702067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NAME_STUDENT': ['Gabriel', 'Fischer'],\n",
       " 'EMAIL': ['gabriel.fischer@gmail.org'],\n",
       " 'STREET_ADDRESS': ['1636', 'Briarview', 'Court']}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_[216]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62de5c51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:20.778622Z",
     "iopub.status.busy": "2024-02-16T14:08:20.777356Z",
     "iopub.status.idle": "2024-02-16T14:08:21.078995Z",
     "shell.execute_reply": "2024-02-16T14:08:21.076937Z"
    },
    "papermill": {
     "duration": 0.326289,
     "end_time": "2024-02-16T14:08:21.083106",
     "exception": false,
     "start_time": "2024-02-16T14:08:20.756817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My - O\n",
      "name - O\n",
      "is - O\n",
      "Joseph - B-NAME_STUDENT\n",
      "Martinez - I-NAME_STUDENT\n",
      ", - O\n",
      "and - O\n",
      "I - O\n",
      "have - O\n",
      "the - O\n",
      "pleasure - O\n",
      "of - O\n",
      "sharing - O\n",
      "my - O\n",
      "life - O\n",
      "'s - O\n",
      "journey - O\n",
      "with - O\n",
      "you - O\n",
      ". - O\n",
      "I - O\n",
      "reside - O\n",
      "at - O\n",
      "22 - B-STREET_ADDRESS\n",
      "Gallatin - I-STREET_ADDRESS\n",
      "Street - I-STREET_ADDRESS\n",
      "Northeast - I-STREET_ADDRESS\n",
      ", - O\n",
      "where - O\n",
      "I - O\n",
      "'ve - O\n",
      "had - O\n",
      "the - O\n",
      "privilege - O\n",
      "of - O\n",
      "calling - O\n",
      "home - O\n",
      "for - O\n",
      "many - O\n",
      "years - O\n",
      ". - O\n",
      "My - O\n",
      "life - O\n",
      "has - O\n",
      "been - O\n",
      "a - O\n",
      "tapestry - O\n",
      "of - O\n",
      "experiences - O\n",
      ", - O\n",
      "both - O\n",
      "joyous - O\n",
      "and - O\n",
      "challenging - O\n",
      ", - O\n",
      "shaping - O\n",
      "me - O\n",
      "into - O\n",
      "the - O\n",
      "person - O\n",
      "I - O\n",
      "am - O\n",
      "today - O\n",
      ". - O\n",
      "From - O\n",
      "a - O\n",
      "tender - O\n",
      "age - O\n",
      ", - O\n",
      "I - O\n",
      "was - O\n",
      "captivated - O\n",
      "by - O\n",
      "the - O\n",
      "written - O\n",
      "word - O\n",
      ". - O\n",
      "I - O\n",
      "spent - O\n",
      "hours - O\n",
      "immersing - O\n",
      "myself - O\n",
      "in - O\n",
      "books - O\n",
      ", - O\n",
      "exploring - O\n",
      "realms - O\n",
      "unknown - O\n",
      "and - O\n",
      "unlocking - O\n",
      "the - O\n",
      "secrets - O\n",
      "of - O\n",
      "the - O\n",
      "world - O\n",
      ". - O\n",
      "My - O\n",
      "passion - O\n",
      "for - O\n",
      "language - O\n",
      "and - O\n",
      "storytelling - O\n",
      "ignited - O\n",
      "a - O\n",
      "desire - O\n",
      "to - O\n",
      "express - O\n",
      "myself - O\n",
      "creatively - O\n",
      ". - O\n",
      "With - O\n",
      "pen - O\n",
      "in - O\n",
      "hand - O\n",
      "and - O\n",
      "heart - O\n",
      "ablaze - O\n",
      ", - O\n",
      "I - O\n",
      "embarked - O\n",
      "on - O\n",
      "a - O\n",
      "literary - O\n",
      "odyssey - O\n",
      ", - O\n",
      "pouring - O\n",
      "my - O\n",
      "thoughts - O\n",
      "and - O\n",
      "emotions - O\n",
      "onto - O\n",
      "paper - O\n",
      ". - O\n",
      "My - O\n",
      "words - O\n",
      "flowed - O\n",
      "freely - O\n",
      ", - O\n",
      "painting - O\n",
      "pictures - O\n",
      "with - O\n",
      "vivid - O\n",
      "hues - O\n",
      "and - O\n",
      "evoking - O\n",
      "emotions - O\n",
      "that - O\n",
      "resonated - O\n",
      "deep - O\n",
      "within - O\n",
      "the - O\n",
      "soul - O\n",
      ". - O\n",
      "Along - O\n",
      "the - O\n",
      "way - O\n",
      ", - O\n",
      "I - O\n",
      "encountered - O\n",
      "both - O\n",
      "triumph - O\n",
      "and - O\n",
      "adversity - O\n",
      ". - O\n",
      "There - O\n",
      "were - O\n",
      "times - O\n",
      "when - O\n",
      "the - O\n",
      "words - O\n",
      "eluded - O\n",
      "me - O\n",
      ", - O\n",
      "leaving - O\n",
      "me - O\n",
      "frustrated - O\n",
      "and - O\n",
      "disheartened - O\n",
      ". - O\n",
      "But - O\n",
      "through - O\n",
      "perseverance - O\n",
      "and - O\n",
      "unwavering - O\n",
      "determination - O\n",
      ", - O\n",
      "I - O\n",
      "learned - O\n",
      "to - O\n",
      "harness - O\n",
      "the - O\n",
      "power - O\n",
      "of - O\n",
      "language - O\n",
      ", - O\n",
      "transforming - O\n",
      "obstacles - O\n",
      "into - O\n",
      "stepping - O\n",
      "stones - O\n",
      "on - O\n",
      "my - O\n",
      "creative - O\n",
      "path - O\n",
      ". - O\n",
      "As - O\n",
      "I - O\n",
      "delved - O\n",
      "deeper - O\n",
      "into - O\n",
      "the - O\n",
      "world - O\n",
      "of - O\n",
      "literature - O\n",
      ", - O\n",
      "I - O\n",
      "discovered - O\n",
      "a - O\n",
      "profound - O\n",
      "connection - O\n",
      "between - O\n",
      "my - O\n",
      "own - O\n",
      "experiences - O\n",
      "and - O\n",
      "the - O\n",
      "stories - O\n",
      "of - O\n",
      "others - O\n",
      ". - O\n",
      "I - O\n",
      "realized - O\n",
      "that - O\n",
      "the - O\n",
      "human - O\n",
      "experience - O\n",
      "is - O\n",
      "a - O\n",
      "shared - O\n",
      "journey - O\n",
      ", - O\n",
      "a - O\n",
      "tapestry - O\n",
      "woven - O\n",
      "from - O\n",
      "countless - O\n",
      "threads - O\n",
      "of - O\n",
      "joy - O\n",
      ", - O\n",
      "sorrow - O\n",
      ", - O\n",
      "love - O\n",
      ", - O\n",
      "and - O\n",
      "loss - O\n",
      ". - O\n",
      "This - O\n",
      "realization - O\n",
      "inspired - O\n",
      "me - O\n",
      "to - O\n",
      "explore - O\n",
      "the - O\n",
      "depths - O\n",
      "of - O\n",
      "the - O\n",
      "human - O\n",
      "condition - O\n",
      ", - O\n",
      "using - O\n",
      "my - O\n",
      "words - O\n",
      "to - O\n",
      "illuminate - O\n",
      "the - O\n",
      "complexities - O\n",
      "of - O\n",
      "life - O\n",
      "and - O\n",
      "the - O\n",
      "resilience - O\n",
      "of - O\n",
      "the - O\n",
      "human - O\n",
      "spirit - O\n",
      ". - O\n",
      "Through - O\n",
      "my - O\n",
      "writing - O\n",
      ", - O\n",
      "I - O\n",
      "have - O\n",
      "endeavored - O\n",
      "to - O\n",
      "capture - O\n",
      "the - O\n",
      "essence - O\n",
      "of - O\n",
      "human - O\n",
      "existence - O\n",
      ", - O\n",
      "to - O\n",
      "give - O\n",
      "voice - O\n",
      "to - O\n",
      "the - O\n",
      "voiceless - O\n",
      ", - O\n",
      "and - O\n",
      "to - O\n",
      "shed - O\n",
      "light - O\n",
      "on - O\n",
      "the - O\n",
      "forgotten - O\n",
      "corners - O\n",
      "of - O\n",
      "society - O\n",
      ". - O\n",
      "My - O\n",
      "goal - O\n",
      "is - O\n",
      "to - O\n",
      "create - O\n",
      "works - O\n",
      "that - O\n",
      "resonate - O\n",
      "with - O\n",
      "readers - O\n",
      "on - O\n",
      "a - O\n",
      "profound - O\n",
      "level - O\n",
      ", - O\n",
      "leaving - O\n",
      "them - O\n",
      "transformed - O\n",
      "and - O\n",
      "inspired - O\n",
      ". - O\n",
      "As - O\n",
      "I - O\n",
      "continue - O\n",
      "on - O\n",
      "this - O\n",
      "literary - O\n",
      "journey - O\n",
      ", - O\n",
      "I - O\n",
      "am - O\n",
      "humbled - O\n",
      "by - O\n",
      "the - O\n",
      "opportunity - O\n",
      "to - O\n",
      "share - O\n",
      "my - O\n",
      "stories - O\n",
      "with - O\n",
      "the - O\n",
      "world - O\n",
      ". - O\n",
      "I - O\n",
      "hope - O\n",
      "that - O\n",
      "my - O\n",
      "words - O\n",
      "will - O\n",
      "touch - O\n",
      "the - O\n",
      "hearts - O\n",
      "of - O\n",
      "many - O\n",
      "and - O\n",
      "leave - O\n",
      "a - O\n",
      "lasting - O\n",
      "impact - O\n",
      "on - O\n",
      "their - O\n",
      "lives - O\n",
      ". - O\n",
      "For - O\n",
      "it - O\n",
      "is - O\n",
      "in - O\n",
      "the - O\n",
      "sharing - O\n",
      "of - O\n",
      "stories - O\n",
      "that - O\n",
      "we - O\n",
      "truly - O\n",
      "connect - O\n",
      "and - O\n",
      "discover - O\n",
      "the - O\n",
      "common - O\n",
      "threads - O\n",
      "that - O\n",
      "bind - O\n",
      "us - O\n",
      "together - O\n",
      "as - O\n",
      "human - O\n",
      "beings - O\n",
      ". - O\n",
      "If - O\n",
      "you - O\n",
      "wish - O\n",
      "to - O\n",
      "reach - O\n",
      "me - O\n",
      ", - O\n",
      "my - O\n",
      "email - O\n",
      "address - O\n",
      "is - O\n",
      "josephmartinez1914@yahoo.gov - B-EMAIL\n",
      ", - O\n",
      "and - O\n",
      "my - O\n",
      "phone - O\n",
      "number - O\n",
      "is - O\n",
      "( - B-PHONE_NUM\n",
      "238 - I-PHONE_NUM\n",
      ") - I-PHONE_NUM\n",
      "151 - I-PHONE_NUM\n",
      "- - I-PHONE_NUM\n",
      "5533 - I-PHONE_NUM\n",
      ". - O\n",
      "I - O\n",
      "welcome - O\n",
      "the - O\n",
      "opportunity - O\n",
      "to - O\n",
      "connect - O\n",
      "with - O\n",
      "fellow - O\n",
      "readers - O\n",
      "and - O\n",
      "engage - O\n",
      "in - O\n",
      "meaningful - O\n",
      "conversations - O\n",
      "about - O\n",
      "literature - O\n",
      "and - O\n",
      "the - O\n",
      "human - O\n",
      "experience - O\n",
      ". - O\n"
     ]
    }
   ],
   "source": [
    "x = new_[new_.document == \"4f9113a4-e372-47a3-b892-dfdc4aded681\"]\n",
    "for t,l in zip(x.tokens, x.labels):\n",
    "    print(t, \"-\", l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8159614",
   "metadata": {
    "papermill": {
     "duration": 0.019062,
     "end_time": "2024-02-16T14:08:21.120571",
     "exception": false,
     "start_time": "2024-02-16T14:08:21.101509",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Turn to aggregated csv - for your convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2635805",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:21.163348Z",
     "iopub.status.busy": "2024-02-16T14:08:21.162716Z",
     "iopub.status.idle": "2024-02-16T14:08:22.320508Z",
     "shell.execute_reply": "2024-02-16T14:08:22.319237Z"
    },
    "papermill": {
     "duration": 1.182849,
     "end_time": "2024-02-16T14:08:22.323377",
     "exception": false,
     "start_time": "2024-02-16T14:08:21.140528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# unexplode columns to lists (technically you can skip this step and safe it exploded instead too)\n",
    "fixed = (\n",
    "    new_.groupby(\"document\")\n",
    "    .agg(\n",
    "        {\n",
    "            \"text\": lambda x: x,\n",
    "            \"tokens\": lambda x: x.tolist(),\n",
    "            \"trailing_whitespace\": lambda x: x.tolist(),\n",
    "            \"labels\": lambda x: x.tolist(),\n",
    "        }\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "# fix text that was turned into list\n",
    "fixed[\"text\"] = fixed.text.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96a7e7fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:22.364927Z",
     "iopub.status.busy": "2024-02-16T14:08:22.364417Z",
     "iopub.status.idle": "2024-02-16T14:08:24.737644Z",
     "shell.execute_reply": "2024-02-16T14:08:24.736795Z"
    },
    "papermill": {
     "duration": 2.39782,
     "end_time": "2024-02-16T14:08:24.739823",
     "exception": false,
     "start_time": "2024-02-16T14:08:22.342003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4434, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed.to_csv(\"pii_dataset_fixed.csv\", index = False)\n",
    "fixed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f99301",
   "metadata": {
    "papermill": {
     "duration": 0.019026,
     "end_time": "2024-02-16T14:08:24.777455",
     "exception": false,
     "start_time": "2024-02-16T14:08:24.758429",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Also save as JSON - as this is the main format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73d4ffce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:24.820288Z",
     "iopub.status.busy": "2024-02-16T14:08:24.819142Z",
     "iopub.status.idle": "2024-02-16T14:08:29.081475Z",
     "shell.execute_reply": "2024-02-16T14:08:29.080340Z"
    },
    "papermill": {
     "duration": 4.287205,
     "end_time": "2024-02-16T14:08:29.084448",
     "exception": false,
     "start_time": "2024-02-16T14:08:24.797243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_format=[]\n",
    "for idx, row in fixed.iterrows():\n",
    "    doc=row[\"document\"]\n",
    "    text=row[\"text\"]\n",
    "    tokens=row[\"tokens\"]\n",
    "    ws=row[\"trailing_whitespace\"]\n",
    "    labels=row[\"labels\"]\n",
    "    \n",
    "    json_format.append(\n",
    "        {\n",
    "            \"document\":doc,\n",
    "            \"full_text\":text,\n",
    "            \"tokens\":tokens,\n",
    "            \"trailing_whitespace\":ws,\n",
    "            \"labels\":labels\n",
    "        }\n",
    "    )\n",
    "import json\n",
    "out_file = open(\"pii_dataset_fixed.json\", \"w\") \n",
    "json.dump(json_format, out_file) \n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7306e35",
   "metadata": {
    "papermill": {
     "duration": 0.018923,
     "end_time": "2024-02-16T14:08:29.123253",
     "exception": false,
     "start_time": "2024-02-16T14:08:29.104330",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Second Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ecb0109d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:29.163690Z",
     "iopub.status.busy": "2024-02-16T14:08:29.162706Z",
     "iopub.status.idle": "2024-02-16T14:08:29.343800Z",
     "shell.execute_reply": "2024-02-16T14:08:29.342596Z"
    },
    "papermill": {
     "duration": 0.203811,
     "end_time": "2024-02-16T14:08:29.346382",
     "exception": false,
     "start_time": "2024-02-16T14:08:29.142571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labeldict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In today's modern world, where technology has ...</td>\n",
       "      <td>{'NAME_STUDENT': ['Richard', 'Chang'], 'EMAIL'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In today's modern world, where technology has ...</td>\n",
       "      <td>{'NAME_STUDENT': [], 'EMAIL': ['tamaramorrison...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Janice: A Student with a Unique Identity\\n\\nIn...</td>\n",
       "      <td>{'NAME_STUDENT': ['Janice'], 'EMAIL': ['laura5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Christian is a student who goes by the usernam...</td>\n",
       "      <td>{'NAME_STUDENT': ['Christian'], 'EMAIL': [], '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In today's modern world, where technology has ...</td>\n",
       "      <td>{'NAME_STUDENT': ['Aaron Smith', 'Fischer', 'T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  In today's modern world, where technology has ...   \n",
       "1  In today's modern world, where technology has ...   \n",
       "2  Janice: A Student with a Unique Identity\\n\\nIn...   \n",
       "3  Christian is a student who goes by the usernam...   \n",
       "4  In today's modern world, where technology has ...   \n",
       "\n",
       "                                           labeldict  \n",
       "0  {'NAME_STUDENT': ['Richard', 'Chang'], 'EMAIL'...  \n",
       "1  {'NAME_STUDENT': [], 'EMAIL': ['tamaramorrison...  \n",
       "2  {'NAME_STUDENT': ['Janice'], 'EMAIL': ['laura5...  \n",
       "3  {'NAME_STUDENT': ['Christian'], 'EMAIL': [], '...  \n",
       "4  {'NAME_STUDENT': ['Aaron Smith', 'Fischer', 'T...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As my first approach was oriented on the column \"1\" of this dataset, this does not need as much pre-processing\n",
    "ai_data = pd.read_csv('/kaggle/input/pii-detection-dataset-gpt/ai_data.csv')\n",
    "ai_data.columns=[\"text\",\"labeldict\"]\n",
    "ai_data.head()\n",
    "\n",
    "# However, as you can see in row 4 - Name student: the dictionary is not consistent and this probably fails our approach\n",
    "# Therefore we have to split on \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3adac49f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:29.387507Z",
     "iopub.status.busy": "2024-02-16T14:08:29.386707Z",
     "iopub.status.idle": "2024-02-16T14:08:32.605208Z",
     "shell.execute_reply": "2024-02-16T14:08:32.603960Z"
    },
    "papermill": {
     "duration": 3.242346,
     "end_time": "2024-02-16T14:08:32.608074",
     "exception": false,
     "start_time": "2024-02-16T14:08:29.365728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pj_to_pj(row):\n",
    "    # wanted format: {\"NAME_STUDENT\":[\"Valentin\", \"Werner\"]}\n",
    "    labeldict={}\n",
    "    for label, pii, in ast.literal_eval(row[\"labeldict\"]).items():\n",
    "        pii_list=[]\n",
    "        for info in pii:\n",
    "            pii_list += tokenize_with_spacy(info)[\"tokens\"]\n",
    "\n",
    "        clean_pii_list=[]\n",
    "        for token in pii_list:\n",
    "            # this string.punctuation filters everything except \"(\" which might be an opening token in phone numbers\n",
    "            while len(token) > 0 and token[-1] in \"\".join(string.punctuation.split(\"(\")): \n",
    "                token=token[:-1]\n",
    "            if len(token) > 0:\n",
    "                clean_pii_list+=[token]\n",
    "        labeldict[label] = clean_pii_list\n",
    "    return labeldict\n",
    "\n",
    "labels_=[]\n",
    "for i, row in ai_data.iterrows():\n",
    "    labeldict=pj_to_pj(row)\n",
    "    labels_.append(labeldict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "731aad35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:32.650096Z",
     "iopub.status.busy": "2024-02-16T14:08:32.649686Z",
     "iopub.status.idle": "2024-02-16T14:08:37.452391Z",
     "shell.execute_reply": "2024-02-16T14:08:37.451158Z"
    },
    "papermill": {
     "duration": 4.827951,
     "end_time": "2024-02-16T14:08:37.454942",
     "exception": false,
     "start_time": "2024-02-16T14:08:32.626991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['tokens', 'trailing_whitespace'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [tokenize_with_spacy(r[\"text\"]) for idx, r in ai_data.iterrows()]\n",
    "tokens[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86d1c0d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:37.495638Z",
     "iopub.status.busy": "2024-02-16T14:08:37.495242Z",
     "iopub.status.idle": "2024-02-16T14:08:39.632109Z",
     "shell.execute_reply": "2024-02-16T14:08:39.630913Z"
    },
    "papermill": {
     "duration": 2.16092,
     "end_time": "2024-02-16T14:08:39.634877",
     "exception": false,
     "start_time": "2024-02-16T14:08:37.473957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This loop is very inefficient, but it takes 0.3 seconds - so who cares\n",
    "\n",
    "new_=[]\n",
    "for tok, l in zip(tokens, labels_):\n",
    "    \n",
    "    # these will just be forwarded to the final result, as we do not change these\n",
    "    t = tok[\"tokens\"]\n",
    "    ws = tok[\"trailing_whitespace\"]\n",
    "    \n",
    "    # Create \"O\" label as standard value to overwrite on specific indices\n",
    "    new_labels=[\"O\"]*len(t)\n",
    "    \n",
    "    # Find entities from labels_ in the text\n",
    "    for ent_type, ent_list in l.items():\n",
    "        for ent_ in ent_list:\n",
    "            # find occurence of tagged entities in the list\n",
    "            # - this assumes that entities are not containing commong words such as \"the\"\n",
    "            indices = [i for i, x in enumerate(t) if x == ent_]\n",
    "            for i in indices:\n",
    "                # overwrite \"O\" label with correct label\n",
    "                new_labels[i] = ent_type\n",
    "    new_.append({\"tokens\":t, \"trailing_whitespace\":ws, \"labels\":new_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ff1d22c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:39.677456Z",
     "iopub.status.busy": "2024-02-16T14:08:39.676954Z",
     "iopub.status.idle": "2024-02-16T14:08:41.750383Z",
     "shell.execute_reply": "2024-02-16T14:08:41.748718Z"
    },
    "papermill": {
     "duration": 2.098878,
     "end_time": "2024-02-16T14:08:41.753609",
     "exception": false,
     "start_time": "2024-02-16T14:08:39.654731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# As we only labelled words, but not punctuation inbetween these words, we need to fill the gaps\n",
    "new_2=[]\n",
    "punctuation = [p for p in string.punctuation]\n",
    "for r, labeldict in zip(new_, labels_):\n",
    "    \n",
    "    sandwich_on_comma = [\"STREET_ADDRESS\"]\n",
    "    # again these are just forwarded\n",
    "    t = r[\"tokens\"]\n",
    "    ws = r[\"trailing_whitespace\"]\n",
    "    # again, these may get overwritten\n",
    "    label = r[\"labels\"]\n",
    "    new_labels=[\"O\"]*len(label)\n",
    "    for i, l in enumerate(label):\n",
    "        # get prior label if possible\n",
    "        if i != 0: prior_label=label[i-1]\n",
    "        else: prior_label=\"O\"\n",
    "\n",
    "        # get next label\n",
    "        if i+1 < len(label): next_label=label[i+1]\n",
    "        elif i+1 == len(label): next_label=\"O\"\n",
    "        \n",
    "        # skip filler / list words that split multiple entities\n",
    "        if (t[i] == \"and\" and l == \"O\") or (t[i] == \"or\" and l == \"O\"):\n",
    "            new_labels[i] = \"O\"\n",
    "        elif (t[i] == \".\" and l == \"O\" and prior_label==\"NAME_STUDENT\"):\n",
    "            new_labels[i] = \"O\"\n",
    "        # \"(\" might be labeled as phone num, which is only correct if more phone num follows\n",
    "        elif t[i] == \"(\" and l == \"PHONE_NUM\" and next_label!=\"PHONE_NUM\":\n",
    "            new_labels[i] = \"O\"\n",
    "        elif t[i] == \"(\" and l != \"PHONE_NUM\":\n",
    "            # print(l, t[i-2:i+5]) # this is whenever we have something like \"my name is Valentin (Valle)\"\n",
    "            new_labels[i] = \"O\"\n",
    "        elif prior_label == \"EMAIL\" and t[i] == \"to\":\n",
    "            new_labels[i] = \"O\"\n",
    "        elif (prior_label == \"NAME_STUDENT\" or prior_label == \"O\") and t[i] == \"'s\":\n",
    "            new_labels[i] = \"O\"\n",
    "        # only street addresses should contain commas - this avoids labelling sandwiches\n",
    "        # which chain multiple entities, such as \"Valentin Werner, Thomas Müller, and Manuel Neuer\"\n",
    "        # As these should be three separate entities\n",
    "        elif t[i] == \",\" and prior_label not in sandwich_on_comma:\n",
    "            new_labels[i] = \"O\"\n",
    "            \n",
    "        # replace if we got a sandwich (\"LABEL\"-\"O\"-\"LABEL\", such as \"Berlin\" - \",\" - \"Germany\")\n",
    "        elif prior_label == next_label and prior_label != \"O\":\n",
    "            new_labels[i] = prior_label\n",
    "        elif l != \"O\":\n",
    "            new_labels[i] = l\n",
    "        else:\n",
    "            new_labels[i] = \"O\"\n",
    "    \n",
    "    new_2.append({\"tokens\":t, \"trailing_whitespace\":ws, \"labels\":new_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08f4fdc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:41.795018Z",
     "iopub.status.busy": "2024-02-16T14:08:41.794402Z",
     "iopub.status.idle": "2024-02-16T14:08:42.265628Z",
     "shell.execute_reply": "2024-02-16T14:08:42.264311Z"
    },
    "papermill": {
     "duration": 0.495308,
     "end_time": "2024-02-16T14:08:42.268814",
     "exception": false,
     "start_time": "2024-02-16T14:08:41.773506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Turn labels into BIO Labels\n",
    "new_bio=[]\n",
    "for i, r in enumerate(new_2):\n",
    "    \n",
    "    # again, these are just forwarded\n",
    "    t = r[\"tokens\"]\n",
    "    ws = r[\"trailing_whitespace\"]\n",
    "    # again, these might get overwritten\n",
    "    label = r[\"labels\"]\n",
    "\n",
    "    # keep track of last label to identify when to use B or I\n",
    "    last_label=\"O\"\n",
    "    for i, l in enumerate(label):\n",
    "        if l != last_label and l != \"O\":\n",
    "            label[i] = \"B-\"+l\n",
    "        elif l == last_label and last_label != \"O\":\n",
    "            label[i] = \"I-\"+l\n",
    "        last_label = l\n",
    "    new_bio.append({\"doc_prelim\":i,\"tokens\":t, \"trailing_whitespace\":ws, \"labels\":label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "849dcdab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:42.308533Z",
     "iopub.status.busy": "2024-02-16T14:08:42.308113Z",
     "iopub.status.idle": "2024-02-16T14:08:42.568170Z",
     "shell.execute_reply": "2024-02-16T14:08:42.567274Z"
    },
    "papermill": {
     "duration": 0.282951,
     "end_time": "2024-02-16T14:08:42.570751",
     "exception": false,
     "start_time": "2024-02-16T14:08:42.287800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1019274, 4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ = pd.DataFrame(new_bio)\n",
    "new_ = new_.explode([\"tokens\", \"trailing_whitespace\", \"labels\"])\n",
    "new_.shape # note that this produces even more tokens than my prior approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "611d4db3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:42.612626Z",
     "iopub.status.busy": "2024-02-16T14:08:42.612196Z",
     "iopub.status.idle": "2024-02-16T14:08:42.627640Z",
     "shell.execute_reply": "2024-02-16T14:08:42.626451Z"
    },
    "papermill": {
     "duration": 0.038679,
     "end_time": "2024-02-16T14:08:42.630039",
     "exception": false,
     "start_time": "2024-02-16T14:08:42.591360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_prelim</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>432</td>\n",
       "      <td>In</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>432</td>\n",
       "      <td>today</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>432</td>\n",
       "      <td>'s</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>432</td>\n",
       "      <td>modern</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>432</td>\n",
       "      <td>world</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>432</td>\n",
       "      <td>,</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>432</td>\n",
       "      <td>where</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>432</td>\n",
       "      <td>technology</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>432</td>\n",
       "      <td>has</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>432</td>\n",
       "      <td>become</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>432</td>\n",
       "      <td>an</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>432</td>\n",
       "      <td>integral</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>432</td>\n",
       "      <td>part</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>432</td>\n",
       "      <td>of</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>432</td>\n",
       "      <td>our</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>432</td>\n",
       "      <td>lives</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>432</td>\n",
       "      <td>,</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>432</td>\n",
       "      <td>it</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>432</td>\n",
       "      <td>is</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>432</td>\n",
       "      <td>essential</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>432</td>\n",
       "      <td>for</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>432</td>\n",
       "      <td>students</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>432</td>\n",
       "      <td>like</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>432</td>\n",
       "      <td>Richard</td>\n",
       "      <td>True</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>432</td>\n",
       "      <td>Chang</td>\n",
       "      <td>True</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_prelim      tokens trailing_whitespace          labels\n",
       "0         432          In                True               O\n",
       "0         432       today               False               O\n",
       "0         432          's                True               O\n",
       "0         432      modern                True               O\n",
       "0         432       world               False               O\n",
       "0         432           ,                True               O\n",
       "0         432       where                True               O\n",
       "0         432  technology                True               O\n",
       "0         432         has                True               O\n",
       "0         432      become                True               O\n",
       "0         432          an                True               O\n",
       "0         432    integral                True               O\n",
       "0         432        part                True               O\n",
       "0         432          of                True               O\n",
       "0         432         our                True               O\n",
       "0         432       lives               False               O\n",
       "0         432           ,                True               O\n",
       "0         432          it                True               O\n",
       "0         432          is                True               O\n",
       "0         432   essential                True               O\n",
       "0         432         for                True               O\n",
       "0         432    students                True               O\n",
       "0         432        like                True               O\n",
       "0         432     Richard                True  B-NAME_STUDENT\n",
       "0         432       Chang                True  I-NAME_STUDENT"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21481b87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:42.671867Z",
     "iopub.status.busy": "2024-02-16T14:08:42.671497Z",
     "iopub.status.idle": "2024-02-16T14:08:43.665223Z",
     "shell.execute_reply": "2024-02-16T14:08:43.664106Z"
    },
    "papermill": {
     "duration": 1.017761,
     "end_time": "2024-02-16T14:08:43.667869",
     "exception": false,
     "start_time": "2024-02-16T14:08:42.650108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pj_0</td>\n",
       "      <td>In today's modern world, where technology has ...</td>\n",
       "      <td>In</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pj_0</td>\n",
       "      <td>In today's modern world, where technology has ...</td>\n",
       "      <td>today</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pj_0</td>\n",
       "      <td>In today's modern world, where technology has ...</td>\n",
       "      <td>'s</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pj_0</td>\n",
       "      <td>In today's modern world, where technology has ...</td>\n",
       "      <td>modern</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pj_0</td>\n",
       "      <td>In today's modern world, where technology has ...</td>\n",
       "      <td>world</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  document                                               text  tokens  \\\n",
       "0     pj_0  In today's modern world, where technology has ...      In   \n",
       "1     pj_0  In today's modern world, where technology has ...   today   \n",
       "2     pj_0  In today's modern world, where technology has ...      's   \n",
       "3     pj_0  In today's modern world, where technology has ...  modern   \n",
       "4     pj_0  In today's modern world, where technology has ...   world   \n",
       "\n",
       "  trailing_whitespace labels  \n",
       "0                True      O  \n",
       "1               False      O  \n",
       "2                True      O  \n",
       "3                True      O  \n",
       "4               False      O  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ = new_.reset_index(names=\"doc_\")\n",
    "new_[\"document\"] = new_.doc_.apply(lambda x: f\"pj_{x}\")\n",
    "\n",
    "# get text from original \n",
    "new_ = pd.merge(new_, ai_data.reset_index(names=\"doc_\")[[\"doc_\",\"text\"]], on=\"doc_\", how=\"left\")\n",
    "new_=new_.drop(columns=[\"doc_prelim\",\"doc_\"])\n",
    "new_=new_[[\"document\",\"text\",\"tokens\",\"trailing_whitespace\",\"labels\"]]\n",
    "new_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68ede7d",
   "metadata": {
    "papermill": {
     "duration": 0.019526,
     "end_time": "2024-02-16T14:08:43.708583",
     "exception": false,
     "start_time": "2024-02-16T14:08:43.689057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sanity checks\n",
    "- only one for this one\n",
    "- please tell me if you see problems with this dataframe!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ff5f214",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:43.750467Z",
     "iopub.status.busy": "2024-02-16T14:08:43.750014Z",
     "iopub.status.idle": "2024-02-16T14:08:43.839092Z",
     "shell.execute_reply": "2024-02-16T14:08:43.837938Z"
    },
    "papermill": {
     "duration": 0.112812,
     "end_time": "2024-02-16T14:08:43.841660",
     "exception": false,
     "start_time": "2024-02-16T14:08:43.728848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same amount of labels as before - if False, check difference - is it correct?\n",
    "new_.labels.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a97913a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:43.884997Z",
     "iopub.status.busy": "2024-02-16T14:08:43.884593Z",
     "iopub.status.idle": "2024-02-16T14:08:44.966104Z",
     "shell.execute_reply": "2024-02-16T14:08:44.964541Z"
    },
    "papermill": {
     "duration": 1.105642,
     "end_time": "2024-02-16T14:08:44.968807",
     "exception": false,
     "start_time": "2024-02-16T14:08:43.863165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O\n",
      "I-URL_PERSONAL\n"
     ]
    }
   ],
   "source": [
    "target = [\n",
    "    'B-EMAIL', 'B-ID_NUM', 'B-NAME_STUDENT', 'B-PHONE_NUM', \n",
    "    'B-STREET_ADDRESS', 'B-URL_PERSONAL', 'B-USERNAME', 'I-ID_NUM', \n",
    "    'I-NAME_STUDENT', 'I-PHONE_NUM', 'I-STREET_ADDRESS', 'I-URL_PERSONAL'\n",
    "]\n",
    "\n",
    "for l in new_.labels.unique():\n",
    "    if l not in target:\n",
    "        print(l)\n",
    "\n",
    "for l in target:\n",
    "    if l not in new_.labels.unique():\n",
    "        print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13ebd47",
   "metadata": {
    "papermill": {
     "duration": 0.01986,
     "end_time": "2024-02-16T14:08:45.009048",
     "exception": false,
     "start_time": "2024-02-16T14:08:44.989188",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Again, aggregated df for your convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3010f9d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:45.053085Z",
     "iopub.status.busy": "2024-02-16T14:08:45.052671Z",
     "iopub.status.idle": "2024-02-16T14:08:45.645763Z",
     "shell.execute_reply": "2024-02-16T14:08:45.644751Z"
    },
    "papermill": {
     "duration": 0.618434,
     "end_time": "2024-02-16T14:08:45.648403",
     "exception": false,
     "start_time": "2024-02-16T14:08:45.029969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# unexplode columns to lists (technically you can skip this step and safe it exploded instead too)\n",
    "fixed = (\n",
    "    new_.groupby(\"document\")\n",
    "    .agg(\n",
    "        {\n",
    "            \"text\": lambda x: x,\n",
    "            \"tokens\": lambda x: x.tolist(),\n",
    "            \"trailing_whitespace\": lambda x: x.tolist(),\n",
    "            \"labels\": lambda x: x.tolist(),\n",
    "        }\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "# fix text that was turned into list\n",
    "fixed[\"text\"] = fixed.text.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a2f22a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:45.692479Z",
     "iopub.status.busy": "2024-02-16T14:08:45.691549Z",
     "iopub.status.idle": "2024-02-16T14:08:47.274617Z",
     "shell.execute_reply": "2024-02-16T14:08:47.273320Z"
    },
    "papermill": {
     "duration": 1.608531,
     "end_time": "2024-02-16T14:08:47.277318",
     "exception": false,
     "start_time": "2024-02-16T14:08:45.668787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed.to_csv(\"moredata_dataset_fixed.csv\", index = False)\n",
    "fixed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1dcc2a",
   "metadata": {
    "papermill": {
     "duration": 0.020028,
     "end_time": "2024-02-16T14:08:47.318012",
     "exception": false,
     "start_time": "2024-02-16T14:08:47.297984",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## also safe as json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9e9fe588",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:47.361223Z",
     "iopub.status.busy": "2024-02-16T14:08:47.360826Z",
     "iopub.status.idle": "2024-02-16T14:08:50.304673Z",
     "shell.execute_reply": "2024-02-16T14:08:50.303469Z"
    },
    "papermill": {
     "duration": 2.969294,
     "end_time": "2024-02-16T14:08:50.307608",
     "exception": false,
     "start_time": "2024-02-16T14:08:47.338314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_format=[]\n",
    "for idx, row in fixed.iterrows():\n",
    "    doc=row[\"document\"]\n",
    "    text=row[\"text\"]\n",
    "    tokens=row[\"tokens\"]\n",
    "    ws=row[\"trailing_whitespace\"]\n",
    "    labels=row[\"labels\"]\n",
    "    \n",
    "    json_format.append(\n",
    "        {\n",
    "            \"document\":doc,\n",
    "            \"full_text\":text,\n",
    "            \"tokens\":tokens,\n",
    "            \"trailing_whitespace\":ws,\n",
    "            \"labels\":labels\n",
    "        }\n",
    "    )\n",
    "import json\n",
    "out_file = open(\"moredata_dataset_fixed.json\", \"w\") \n",
    "json.dump(json_format, out_file) \n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bceac026",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T14:08:50.353217Z",
     "iopub.status.busy": "2024-02-16T14:08:50.352769Z",
     "iopub.status.idle": "2024-02-16T14:08:50.359854Z",
     "shell.execute_reply": "2024-02-16T14:08:50.358945Z"
    },
    "papermill": {
     "duration": 0.031786,
     "end_time": "2024-02-16T14:08:50.362069",
     "exception": false,
     "start_time": "2024-02-16T14:08:50.330283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "463"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_format[20][\"tokens\"])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7500999,
     "sourceId": 66653,
     "sourceType": "competition"
    },
    {
     "datasetId": 4332496,
     "sourceId": 7466758,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4356764,
     "sourceId": 7483989,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 75.644946,
   "end_time": "2024-02-16T14:08:52.110075",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-16T14:07:36.465129",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
